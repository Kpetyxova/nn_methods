{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### –ü–µ—Ç—É—Ö–æ–≤–∞ –ö—Å–µ–Ω–∏—è –ë–ö–õ182"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –≤—Å–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –¥–ª—è –¥–∞–ª—å–Ω–µ–π—à–µ–π —Ä–∞–±–æ—Ç—ã –º–æ–¥—É–ª–∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/kseniapetuhova/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "from string import punctuation\n",
    "import nltk\n",
    "nltk.download(\"stopwords\")\n",
    "from nltk.corpus import stopwords\n",
    "morph = MorphAnalyzer()\n",
    "english_stopwords = stopwords.words(\"english\")\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import *\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import preprocessing\n",
    "from sklearn import utils\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–í–≤–µ–¥–∏—Ç–µ –ø—É—Ç—å –¥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞: /Users/kseniapetuhova/Desktop/Shoes_Data.csv\n"
     ]
    }
   ],
   "source": [
    "path = input('–í–≤–µ–¥–∏—Ç–µ –ø—É—Ç—å –¥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞: ')\n",
    "shoes_data = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ò–∑–≤–ª–µ–∫–∞–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏:\n",
    "* –¥–ª–∏–Ω–∞ –Ω–∞–∑–≤–∞–Ω–∏—è —Ç–æ–≤–∞—Ä–∞\n",
    "* –¥–ª–∏–Ω–∞ –æ–ø–∏—Å–∞–Ω–∏—è —Ç–æ–≤–∞—Ä–∞\n",
    "* —Å—Ä–µ–¥–Ω—è—è –¥–ª–∏–Ω–∞ –æ—Ç–∑—ã–≤–∞ –Ω–∞ —Ç–æ–≤–∞—Ä\n",
    "\n",
    "–¢–∞–∫–∂–µ –ø—Ä–∏–≤–æ–¥–∏–º –¥—Ä—É–≥–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –∫ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ–º—É —Ñ–æ—Ä–º–∞—Ç—É"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1230it [00:00, 2200.28it/s]\n"
     ]
    }
   ],
   "source": [
    "len_title = []\n",
    "price_new = []\n",
    "rating_new = []\n",
    "total_reviews_new = []\n",
    "len_product_description = []\n",
    "mean_len_reviews = []\n",
    "shoe_type = []\n",
    "for index, row in tqdm(shoes_data.iterrows()):\n",
    "    len_title.append(len(row['title']))\n",
    "    price_new.append(float(row['price'][1:]))\n",
    "    rating_new.append(float(row['rating'][:3]))\n",
    "    t_r = row['total_reviews'].replace(' ratings', '')\n",
    "    t_r = t_r.replace(' rating', '')\n",
    "    total_reviews_new.append(int(t_r))\n",
    "    len_product_description.append(len(row['product_description']))\n",
    "    splitted_rev = row['reviews'].split('||')\n",
    "    len_rev = [len(i) for i in splitted_rev]\n",
    "    sum_len_rev = 0\n",
    "    for l in len_rev:\n",
    "        sum_len_rev += l\n",
    "    mean_len_rev = sum_len_rev / len(len_rev)\n",
    "    mean_len_reviews.append(mean_len_rev)\n",
    "    if row['Shoe Type'] == 'Men':\n",
    "        shoe_type.append(0)\n",
    "    else:\n",
    "        shoe_type.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "shoes_data_new = shoes_data.copy()\n",
    "shoes_data_new['len_title'] = len_title\n",
    "shoes_data_new['price_new'] = price_new\n",
    "shoes_data_new['rating_new'] = rating_new\n",
    "shoes_data_new['total_reviews_new'] = total_reviews_new\n",
    "shoes_data_new['len_product_description'] = len_product_description\n",
    "shoes_data_new['mean_len_reviews'] = mean_len_reviews\n",
    "shoes_data_new['shoe_type'] = shoe_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>price</th>\n",
       "      <th>rating</th>\n",
       "      <th>total_reviews</th>\n",
       "      <th>product_description</th>\n",
       "      <th>reviews</th>\n",
       "      <th>reviews_rating</th>\n",
       "      <th>Shoe Type</th>\n",
       "      <th>len_title</th>\n",
       "      <th>price_new</th>\n",
       "      <th>rating_new</th>\n",
       "      <th>total_reviews_new</th>\n",
       "      <th>len_product_description</th>\n",
       "      <th>mean_len_reviews</th>\n",
       "      <th>shoe_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CLYMB Outdoor Sports Running Shoes for Mens Boy</td>\n",
       "      <td>‚Çπ279.00</td>\n",
       "      <td>2.9 out of 5 stars</td>\n",
       "      <td>2389 ratings</td>\n",
       "      <td>Elevate your style with this classy pair of Ru...</td>\n",
       "      <td>Not happy with product|| It's not as expected....</td>\n",
       "      <td>1.0 out of 5 stars|| 1.0 out of 5 stars|| 3.0 ...</td>\n",
       "      <td>Men</td>\n",
       "      <td>47</td>\n",
       "      <td>279.0</td>\n",
       "      <td>2.9</td>\n",
       "      <td>2389</td>\n",
       "      <td>222</td>\n",
       "      <td>27.9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bourge Men's Loire-z126 Running Shoes</td>\n",
       "      <td>‚Çπ479.00</td>\n",
       "      <td>3.9 out of 5 stars</td>\n",
       "      <td>11520 ratings</td>\n",
       "      <td>The product will be an excellent pick for you....</td>\n",
       "      <td>Memory cushioning in these shoes is the best f...</td>\n",
       "      <td>5.0 out of 5 stars|| 1.0 out of 5 stars|| 5.0 ...</td>\n",
       "      <td>Men</td>\n",
       "      <td>37</td>\n",
       "      <td>479.0</td>\n",
       "      <td>3.9</td>\n",
       "      <td>11520</td>\n",
       "      <td>78</td>\n",
       "      <td>28.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T-Rock Men's Sneaker</td>\n",
       "      <td>‚Çπ430.00</td>\n",
       "      <td>3.3 out of 5 stars</td>\n",
       "      <td>1251 ratings</td>\n",
       "      <td>Flaunt with these stylish and unique red casua...</td>\n",
       "      <td>Worth to its amount|| Go for it|| Perfect|| 5 ...</td>\n",
       "      <td>5.0 out of 5 stars|| 5.0 out of 5 stars|| 5.0 ...</td>\n",
       "      <td>Men</td>\n",
       "      <td>20</td>\n",
       "      <td>430.0</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1251</td>\n",
       "      <td>398</td>\n",
       "      <td>16.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Robbie jones Sneakers Casual Canvas Fabric Col...</td>\n",
       "      <td>‚Çπ499.00</td>\n",
       "      <td>4.2 out of 5 stars</td>\n",
       "      <td>3 ratings</td>\n",
       "      <td>Robbie Jones Shoes Are Designed To Keeping In ...</td>\n",
       "      <td>Sup quality|| Good but not expected|| Awesome üëå.!</td>\n",
       "      <td>5.0 out of 5 stars|| 3.0 out of 5 stars|| 5.0 ...</td>\n",
       "      <td>Men</td>\n",
       "      <td>72</td>\n",
       "      <td>499.0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>3</td>\n",
       "      <td>576</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sparx Men's Sd0323g Sneakers</td>\n",
       "      <td>‚Çπ499.00</td>\n",
       "      <td>4.2 out of 5 stars</td>\n",
       "      <td>20110 ratings</td>\n",
       "      <td>Sparx is a spectacular range of footwear from ...</td>\n",
       "      <td>Best|| Satisfied!|| Affordable beauty üòòüòòüòòüòò the...</td>\n",
       "      <td>5.0 out of 5 stars|| 5.0 out of 5 stars|| 5.0 ...</td>\n",
       "      <td>Men</td>\n",
       "      <td>28</td>\n",
       "      <td>499.0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>20110</td>\n",
       "      <td>1030</td>\n",
       "      <td>30.6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1225</th>\n",
       "      <td>Nike Men's React Vision Running Shoes</td>\n",
       "      <td>‚Çπ7256.00</td>\n",
       "      <td>4.4 out of 5 stars</td>\n",
       "      <td>200 ratings</td>\n",
       "      <td>The Nike react vision is a STORY of surreal co...</td>\n",
       "      <td>Must buy|| not have a great fiting but great q...</td>\n",
       "      <td>5.0 out of 5 stars|| 3.0 out of 5 stars|| 5.0 ...</td>\n",
       "      <td>Women</td>\n",
       "      <td>37</td>\n",
       "      <td>7256.0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>200</td>\n",
       "      <td>237</td>\n",
       "      <td>18.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1226</th>\n",
       "      <td>Puma Men's B.O.G Limitless Hi Evoknit Sneakers</td>\n",
       "      <td>‚Çπ5822.00</td>\n",
       "      <td>4.3 out of 5 stars</td>\n",
       "      <td>25 ratings</td>\n",
       "      <td>The B.O.G limitless is Puma's key style for th...</td>\n",
       "      <td>Worth buying !|| Classy Bold and Stylish !!|| ...</td>\n",
       "      <td>4.0 out of 5 stars|| 5.0 out of 5 stars|| 3.0 ...</td>\n",
       "      <td>Women</td>\n",
       "      <td>46</td>\n",
       "      <td>5822.0</td>\n",
       "      <td>4.3</td>\n",
       "      <td>25</td>\n",
       "      <td>876</td>\n",
       "      <td>14.3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1227</th>\n",
       "      <td>new balance Women's FuelCell Echolucent Runnin...</td>\n",
       "      <td>‚Çπ5362.00</td>\n",
       "      <td>4.5 out of 5 stars</td>\n",
       "      <td>817 ratings</td>\n",
       "      <td>Lead the pack in New Balance‚Äôs Echolucent snea...</td>\n",
       "      <td>size variation in product recd n size chart|| ...</td>\n",
       "      <td>5.0 out of 5 stars|| 5.0 out of 5 stars|| 5.0 ...</td>\n",
       "      <td>Women</td>\n",
       "      <td>52</td>\n",
       "      <td>5362.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>817</td>\n",
       "      <td>311</td>\n",
       "      <td>17.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1228</th>\n",
       "      <td>Nike Women's WMNS Air Zoom Pegasus 37 Running ...</td>\n",
       "      <td>‚Çπ7480.00</td>\n",
       "      <td>4.5 out of 5 stars</td>\n",
       "      <td>67 ratings</td>\n",
       "      <td>Nike ‡∞Æ‡∞π‡∞ø‡∞≥‡∞≤ ‡∞∞‡∞®‡±ç‡∞®‡∞ø‡∞Ç‡∞ó‡±ç ‡∞∑‡±Ç ‡∞´‡±Ä‡∞≤‡±ç‡∞∏‡±ç ‡∞Æ‡∞∞‡∞ø‡∞Ø‡±Å ‡∞∞‡±Ç‡∞™‡∞Ç ‡∞Æ‡±É‡∞¶‡±Å‡∞µ...</td>\n",
       "      <td>Verified Purchase|| Verified Purchase|| Verifi...</td>\n",
       "      <td>5.0 out of 5 stars|| 5.0 out of 5 stars|| 4.0 ...</td>\n",
       "      <td>Women</td>\n",
       "      <td>50</td>\n",
       "      <td>7480.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>67</td>\n",
       "      <td>1629</td>\n",
       "      <td>14.9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1229</th>\n",
       "      <td>ASICS Women Gt-2000 7 Lite-Show Running Shoes</td>\n",
       "      <td>‚Çπ5719.00</td>\n",
       "      <td>4.1 out of 5 stars</td>\n",
       "      <td>210 ratings</td>\n",
       "      <td>The GT-2000 7 achieves a reassuringly firm rid...</td>\n",
       "      <td>Great shoe|| excellent quality|| Old manufactu...</td>\n",
       "      <td>5.0 out of 5 stars|| 5.0 out of 5 stars|| 3.0 ...</td>\n",
       "      <td>Women</td>\n",
       "      <td>45</td>\n",
       "      <td>5719.0</td>\n",
       "      <td>4.1</td>\n",
       "      <td>210</td>\n",
       "      <td>153</td>\n",
       "      <td>19.9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1230 rows √ó 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title     price  \\\n",
       "0       CLYMB Outdoor Sports Running Shoes for Mens Boy   ‚Çπ279.00   \n",
       "1                 Bourge Men's Loire-z126 Running Shoes   ‚Çπ479.00   \n",
       "2                                  T-Rock Men's Sneaker   ‚Çπ430.00   \n",
       "3     Robbie jones Sneakers Casual Canvas Fabric Col...   ‚Çπ499.00   \n",
       "4                          Sparx Men's Sd0323g Sneakers   ‚Çπ499.00   \n",
       "...                                                 ...       ...   \n",
       "1225              Nike Men's React Vision Running Shoes  ‚Çπ7256.00   \n",
       "1226     Puma Men's B.O.G Limitless Hi Evoknit Sneakers  ‚Çπ5822.00   \n",
       "1227  new balance Women's FuelCell Echolucent Runnin...  ‚Çπ5362.00   \n",
       "1228  Nike Women's WMNS Air Zoom Pegasus 37 Running ...  ‚Çπ7480.00   \n",
       "1229      ASICS Women Gt-2000 7 Lite-Show Running Shoes  ‚Çπ5719.00   \n",
       "\n",
       "                  rating  total_reviews  \\\n",
       "0     2.9 out of 5 stars   2389 ratings   \n",
       "1     3.9 out of 5 stars  11520 ratings   \n",
       "2     3.3 out of 5 stars   1251 ratings   \n",
       "3     4.2 out of 5 stars      3 ratings   \n",
       "4     4.2 out of 5 stars  20110 ratings   \n",
       "...                  ...            ...   \n",
       "1225  4.4 out of 5 stars    200 ratings   \n",
       "1226  4.3 out of 5 stars     25 ratings   \n",
       "1227  4.5 out of 5 stars    817 ratings   \n",
       "1228  4.5 out of 5 stars     67 ratings   \n",
       "1229  4.1 out of 5 stars    210 ratings   \n",
       "\n",
       "                                    product_description  \\\n",
       "0     Elevate your style with this classy pair of Ru...   \n",
       "1     The product will be an excellent pick for you....   \n",
       "2     Flaunt with these stylish and unique red casua...   \n",
       "3     Robbie Jones Shoes Are Designed To Keeping In ...   \n",
       "4     Sparx is a spectacular range of footwear from ...   \n",
       "...                                                 ...   \n",
       "1225  The Nike react vision is a STORY of surreal co...   \n",
       "1226  The B.O.G limitless is Puma's key style for th...   \n",
       "1227  Lead the pack in New Balance‚Äôs Echolucent snea...   \n",
       "1228  Nike ‡∞Æ‡∞π‡∞ø‡∞≥‡∞≤ ‡∞∞‡∞®‡±ç‡∞®‡∞ø‡∞Ç‡∞ó‡±ç ‡∞∑‡±Ç ‡∞´‡±Ä‡∞≤‡±ç‡∞∏‡±ç ‡∞Æ‡∞∞‡∞ø‡∞Ø‡±Å ‡∞∞‡±Ç‡∞™‡∞Ç ‡∞Æ‡±É‡∞¶‡±Å‡∞µ...   \n",
       "1229  The GT-2000 7 achieves a reassuringly firm rid...   \n",
       "\n",
       "                                                reviews  \\\n",
       "0     Not happy with product|| It's not as expected....   \n",
       "1     Memory cushioning in these shoes is the best f...   \n",
       "2     Worth to its amount|| Go for it|| Perfect|| 5 ...   \n",
       "3     Sup quality|| Good but not expected|| Awesome üëå.!   \n",
       "4     Best|| Satisfied!|| Affordable beauty üòòüòòüòòüòò the...   \n",
       "...                                                 ...   \n",
       "1225  Must buy|| not have a great fiting but great q...   \n",
       "1226  Worth buying !|| Classy Bold and Stylish !!|| ...   \n",
       "1227  size variation in product recd n size chart|| ...   \n",
       "1228  Verified Purchase|| Verified Purchase|| Verifi...   \n",
       "1229  Great shoe|| excellent quality|| Old manufactu...   \n",
       "\n",
       "                                         reviews_rating Shoe Type  len_title  \\\n",
       "0     1.0 out of 5 stars|| 1.0 out of 5 stars|| 3.0 ...       Men         47   \n",
       "1     5.0 out of 5 stars|| 1.0 out of 5 stars|| 5.0 ...       Men         37   \n",
       "2     5.0 out of 5 stars|| 5.0 out of 5 stars|| 5.0 ...       Men         20   \n",
       "3     5.0 out of 5 stars|| 3.0 out of 5 stars|| 5.0 ...       Men         72   \n",
       "4     5.0 out of 5 stars|| 5.0 out of 5 stars|| 5.0 ...       Men         28   \n",
       "...                                                 ...       ...        ...   \n",
       "1225  5.0 out of 5 stars|| 3.0 out of 5 stars|| 5.0 ...     Women         37   \n",
       "1226  4.0 out of 5 stars|| 5.0 out of 5 stars|| 3.0 ...     Women         46   \n",
       "1227  5.0 out of 5 stars|| 5.0 out of 5 stars|| 5.0 ...     Women         52   \n",
       "1228  5.0 out of 5 stars|| 5.0 out of 5 stars|| 4.0 ...     Women         50   \n",
       "1229  5.0 out of 5 stars|| 5.0 out of 5 stars|| 3.0 ...     Women         45   \n",
       "\n",
       "      price_new  rating_new  total_reviews_new  len_product_description  \\\n",
       "0         279.0         2.9               2389                      222   \n",
       "1         479.0         3.9              11520                       78   \n",
       "2         430.0         3.3               1251                      398   \n",
       "3         499.0         4.2                  3                      576   \n",
       "4         499.0         4.2              20110                     1030   \n",
       "...         ...         ...                ...                      ...   \n",
       "1225     7256.0         4.4                200                      237   \n",
       "1226     5822.0         4.3                 25                      876   \n",
       "1227     5362.0         4.5                817                      311   \n",
       "1228     7480.0         4.5                 67                     1629   \n",
       "1229     5719.0         4.1                210                      153   \n",
       "\n",
       "      mean_len_reviews  shoe_type  \n",
       "0                 27.9          0  \n",
       "1                 28.2          0  \n",
       "2                 16.4          0  \n",
       "3                 15.0          0  \n",
       "4                 30.6          0  \n",
       "...                ...        ...  \n",
       "1225              18.4          1  \n",
       "1226              14.3          1  \n",
       "1227              17.5          1  \n",
       "1228              14.9          1  \n",
       "1229              19.9          1  \n",
       "\n",
       "[1230 rows x 15 columns]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shoes_data_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–í–∏–∑—É–∞–ª–∏–∑–∏—Ä—É–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –¥–∞–Ω–Ω—ã—Ö"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>len_title</th>\n",
       "      <th>price_new</th>\n",
       "      <th>rating_new</th>\n",
       "      <th>total_reviews_new</th>\n",
       "      <th>len_product_description</th>\n",
       "      <th>mean_len_reviews</th>\n",
       "      <th>shoe_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1230.000000</td>\n",
       "      <td>1230.000000</td>\n",
       "      <td>1230.000000</td>\n",
       "      <td>1230.000000</td>\n",
       "      <td>1230.000000</td>\n",
       "      <td>1230.000000</td>\n",
       "      <td>1230.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>42.763415</td>\n",
       "      <td>2031.842268</td>\n",
       "      <td>3.964553</td>\n",
       "      <td>815.791057</td>\n",
       "      <td>502.500000</td>\n",
       "      <td>20.717062</td>\n",
       "      <td>0.304065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>20.524057</td>\n",
       "      <td>1729.425360</td>\n",
       "      <td>0.468047</td>\n",
       "      <td>3116.057954</td>\n",
       "      <td>805.058406</td>\n",
       "      <td>6.827617</td>\n",
       "      <td>0.460197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>127.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>31.000000</td>\n",
       "      <td>622.250000</td>\n",
       "      <td>3.800000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>195.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>38.000000</td>\n",
       "      <td>1588.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>118.000000</td>\n",
       "      <td>288.000000</td>\n",
       "      <td>19.550000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>47.000000</td>\n",
       "      <td>2844.687500</td>\n",
       "      <td>4.200000</td>\n",
       "      <td>440.750000</td>\n",
       "      <td>560.000000</td>\n",
       "      <td>24.700000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>193.000000</td>\n",
       "      <td>7992.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>42193.000000</td>\n",
       "      <td>11855.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         len_title    price_new   rating_new  total_reviews_new  \\\n",
       "count  1230.000000  1230.000000  1230.000000        1230.000000   \n",
       "mean     42.763415  2031.842268     3.964553         815.791057   \n",
       "std      20.524057  1729.425360     0.468047        3116.057954   \n",
       "min       5.000000   127.000000     1.000000           1.000000   \n",
       "25%      31.000000   622.250000     3.800000          26.000000   \n",
       "50%      38.000000  1588.000000     4.000000         118.000000   \n",
       "75%      47.000000  2844.687500     4.200000         440.750000   \n",
       "max     193.000000  7992.000000     5.000000       42193.000000   \n",
       "\n",
       "       len_product_description  mean_len_reviews    shoe_type  \n",
       "count              1230.000000       1230.000000  1230.000000  \n",
       "mean                502.500000         20.717062     0.304065  \n",
       "std                 805.058406          6.827617     0.460197  \n",
       "min                   1.000000          3.000000     0.000000  \n",
       "25%                 195.000000         16.000000     0.000000  \n",
       "50%                 288.000000         19.550000     0.000000  \n",
       "75%                 560.000000         24.700000     1.000000  \n",
       "max               11855.000000         55.000000     1.000000  "
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shoes_data_new.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1230 entries, 0 to 1229\n",
      "Data columns (total 15 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   title                    1230 non-null   object \n",
      " 1   price                    1230 non-null   object \n",
      " 2   rating                   1230 non-null   object \n",
      " 3   total_reviews            1230 non-null   object \n",
      " 4   product_description      1230 non-null   object \n",
      " 5   reviews                  1230 non-null   object \n",
      " 6   reviews_rating           1230 non-null   object \n",
      " 7   Shoe Type                1230 non-null   object \n",
      " 8   len_title                1230 non-null   int64  \n",
      " 9   price_new                1230 non-null   float64\n",
      " 10  rating_new               1230 non-null   float64\n",
      " 11  total_reviews_new        1230 non-null   int64  \n",
      " 12  len_product_description  1230 non-null   int64  \n",
      " 13  mean_len_reviews         1230 non-null   float64\n",
      " 14  shoe_type                1230 non-null   int64  \n",
      "dtypes: float64(3), int64(4), object(8)\n",
      "memory usage: 144.3+ KB\n"
     ]
    }
   ],
   "source": [
    "shoes_data_new.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "sns.heatmap(data=shoes_data_new.corr(), \n",
    "            annot=True, ax=ax)\n",
    "plt.title(\"–ö–æ—Ä—Ä–µ–ª—è—Ü–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'number of entries')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "shoes_data['Shoe Type'].value_counts().plot.bar(color='pink');\n",
    "plt.title('shoe_type')\n",
    "plt.xlabel('shoe_type')\n",
    "plt.xlabel('number of entries')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –ó–∞–¥–∞–Ω–∏–µ 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –ú—ã —É–∂–µ –ø–æ—Å–º–æ—Ç—Ä–µ–ª–∏ –Ω–∞ –æ–±—â—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –¥–∞–Ω–Ω—ã—Ö, –ø–æ—ç—Ç–æ–º—É —Ç–µ–ø–µ—Ä—å –ø–æ—Å–º–æ—Ç—Ä–∏–º –Ω–∞ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ –¥–ª—è –ø–µ—Ä–≤–æ–π –∑–∞–¥–∞—á–∏ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ü–µ–Ω —Ç–æ–≤–∞—Ä–æ–≤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.distplot(shoes_data_new['price_new'], bins=17, color='pink')\n",
    "plt.title('Distribution of prices')\n",
    "plt.ylabel('%')\n",
    "plt.xlabel('Price');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –æ—Ü–µ–Ω–æ–∫ —Ç–æ–≤–∞—Ä–æ–≤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fc322f97ca0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "shoes_data_new['rating_new'].plot(kind='hist', figsize=(5, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def likes():\n",
    "    list_mentioned = list(shoes_data_new.rating_new.unique())\n",
    "    dict_amount = {}\n",
    "    dict_likes = {}\n",
    "    for x in list_mentioned:\n",
    "        counter = 0\n",
    "        if x != 'nan':\n",
    "            likes_per_person = shoes_data_new[shoes_data_new.rating_new == x].price_new\n",
    "            l = list(likes_per_person)\n",
    "            dict_amount[x] = len(list(l))\n",
    "            for i in l:\n",
    "                counter += i\n",
    "            dict_likes[x] = counter\n",
    "    return dict_amount, dict_likes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def medium(dict_amount, dict_likes):\n",
    "    med_likes = {}\n",
    "    for key in dict_likes:\n",
    "        try:\n",
    "            s = dict_likes[key]/dict_amount[key]\n",
    "            med_likes[key] = round(s)\n",
    "        except:\n",
    "            continue\n",
    "    a = sorted(med_likes.items(), key=lambda x: x[1], reverse=True)[:15]\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph(a):\n",
    "    nums = [w[-1] for w in a]\n",
    "    labs = [w[0] for w in a]\n",
    "    plt.figure(figsize=(20, 10), dpi=200)\n",
    "    plt.bar(range(len(labs)), nums)\n",
    "\n",
    "    plt.title('–°—Ä–µ–¥–Ω—è—è —Ü–µ–Ω–∞ —Ç–æ–≤–∞—Ä–æ–≤, –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Å—Ä–µ–¥–Ω–∏—Ö —Ä–µ–π—Ç–∏–Ω–≥–æ–≤')\n",
    "    plt.ylabel('–°—Ä–µ–¥–Ω—è—è —Ü–µ–Ω–∞ —Ç–æ–≤–∞—Ä–æ–≤')\n",
    "    plt.xlabel('–°—Ä–µ–¥–Ω–∏–π —Ä–µ–π—Ç–∏–Ω–≥ —Ç–æ–≤–∞—Ä–æ–≤')\n",
    "    plt.xticks(range(len(labs)), labs, rotation=90)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = likes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = medium(dl[0], dl[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 4000x2000 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "graph(h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–¢–∞–∫–∏–º –æ–±—Ä–∞–∑–æ–º: \n",
    "\n",
    "1) –¶–µ–Ω—ã –Ω–∞ –æ–±—É–≤—å –Ω–∞—Ö–æ–¥—è—Ç—Å—è –≤ –ø—Ä–æ–º–µ–∂—É—Ç–∫–µ –æ—Ç 127 –¥–æ 7992 —Ä—É–ø–∏–π, –ø—Ä–∏ —ç—Ç–æ–º –±–û–ª—å—à–∞—è —á–∞—Å—Ç—å –æ–±—É–≤–∏ —Å—Ç–æ–∏—Ç –¥–æ 1000 —Ä—É–ø–∏–π\n",
    "\n",
    "2) –°–∞–º—ã–µ —á–∞—Å—Ç–æ—Ç–Ω—ã–µ —Å—Ä–µ–¥–Ω–∏–µ –æ—Ü–µ–Ω–∫–∏ —Ç–æ–≤–∞—Ä–æ–≤: 4.0, 4.5 –∏ 3.5\n",
    "\n",
    "3) –°–∞–º—ã–π –Ω–∏–∑–∫–∏–π —Ä–µ–π—Ç–∏–Ω–≥ –∏–º–µ–µ—Ç —Å–∞–º–∞—è –¥–æ—Ä–æ–≥–∞—è –æ–±—É–≤—å; —Å–∞–º—ã–π –≤—ã—Å–æ–∫–∏–π —Ä–µ–π—Ç–∏–Ω–≥ –∏–º–µ–µ—Ç –æ–±—É–≤—å —Å–æ —Å—Ä–µ–¥–Ω–µ–π —Å—Ç–æ–∏–º–æ—Å—Ç—å—é (–ø—Ä–∏–º–µ—Ä–Ω–æ 3500 —Ä—É–ø–∏–π); –æ–±—É–≤—å —Å —Ä–µ–π—Ç–∏–Ω–≥–æ–º 4.2 –∏ 3.5 –∏–º–µ–µ—Ç —Å–∞–º—É—é –Ω–∏–∑–∫—É—é —Ü–µ–Ω—É"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –ü—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–Ø –ø—Ä–∏–≤–æ–∂—É –≤—Å–µ –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É, –¥–µ–ª–∞—é –ª–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏—é, —É–±–∏—Ä–∞—é –ø—É–Ω–∫—Ç—É–∞—Ü–∏—é –∏ —Å—Ç–æ–ø —Å–ª–æ–≤–∞. –Ø –Ω–µ –¥–µ–ª–∞—é —Å—Ç–µ–º–º–∏–Ω–≥, –ø–æ—Ç–æ–º—É —á—Ç–æ –æ–Ω –º–æ–∂–µ—Ç –ø—Ä–∏–≤–µ—Å—Ç–∏ –∫ –ø–æ—Ç–µ—Ä–µ –º–æ—Ä—Ñ–æ–ª–æ–≥–∏—á–µ—Å–∫–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏, –≤ —Ç–æ–º —á–∏—Å–ª–µ —á–∞—Å—Ç–µ–π —Ä–µ—á–∏."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(texts):\n",
    "    preprocessed_texts = []\n",
    "    for text in tqdm(texts):\n",
    "        preprocessed_texts.append(' '.join(morph.parse(w.strip(punctuation))[0].normal_form for w in text.split()\n",
    "                                           if w not in english_stopwords))\n",
    "\n",
    "    return preprocessed_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_description = list(shoes_data_new[\"product_description\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1230/1230 [00:03<00:00, 374.00it/s]\n"
     ]
    }
   ],
   "source": [
    "product_description_prep = preprocessing(product_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "shoes_data_new['product_description_prep'] = product_description_prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = list(shoes_data_new[\"title\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1230/1230 [00:00<00:00, 3646.75it/s]\n"
     ]
    }
   ],
   "source": [
    "title_prep = preprocessing(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "shoes_data_new['title_prep'] = title_prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = list(shoes_data_new[\"reviews\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1230/1230 [00:01<00:00, 1148.23it/s]\n"
     ]
    }
   ],
   "source": [
    "reviews_prep = preprocessing(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "shoes_data_new['reviews_prep'] = reviews_prep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –í–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—è"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–í shoes_data_new –≤ –¥–∞–ª—å–Ω–µ–π—à–µ–º –ø–æ–ª–æ–∂–∏–º –≤–µ–∫—Ç–æ—Ä–∞ BoW (CountVectorizer), –∞ –≤ shoes_data_new_2 - –≤–µ–∫—Ç–æ—Ä–∞ TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "shoes_data_new_2 = shoes_data_new.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–í–µ–∫—Ç–æ—Ä–∏–∑—É–µ–º –Ω–∞–∑–≤–∞–Ω–∏—è, –æ–ø–∏—Å–∞–Ω–∏—è –∏ –æ—Ç–∑—ã–≤—ã —Å –ø–æ–º–æ—â—å—é CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(analyzer='word')\n",
    "X = vectorizer.fit_transform(title_prep)\n",
    "columns = ['title_' + str(i) for i in range(X.shape[1])]\n",
    "c_v_df = pd.DataFrame(X.todense(), columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "shoes_data_new = pd.concat([shoes_data_new, c_v_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(analyzer='word')\n",
    "X = vectorizer.fit_transform(reviews_prep)\n",
    "columns = ['reviews_' + str(i) for i in range(X.shape[1])]\n",
    "c_v_df = pd.DataFrame(X.todense(), columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "shoes_data_new = pd.concat([shoes_data_new, c_v_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(analyzer='word')\n",
    "X = vectorizer.fit_transform(product_description_prep)\n",
    "columns = ['product_description_' + str(i) for i in range(X.shape[1])]\n",
    "c_v_df = pd.DataFrame(X.todense(), columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "shoes_data_new = pd.concat([shoes_data_new, c_v_df], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–í–µ–∫—Ç–æ—Ä–∏–∑—É–µ–º –Ω–∞–∑–≤–∞–Ω–∏—è, –æ–ø–∏—Å–∞–Ω–∏—è –∏ –æ—Ç–∑—ã–≤—ã —Å –ø–æ–º–æ—â—å—é TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(title_prep)\n",
    "columns = ['title_' + str(i) for i in range(X.shape[1])]\n",
    "c_v_df = pd.DataFrame(X.todense(), columns=columns)\n",
    "shoes_data_new_2 = pd.concat([shoes_data_new_2, c_v_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(reviews_prep)\n",
    "columns = ['reviews_' + str(i) for i in range(X.shape[1])]\n",
    "c_v_df = pd.DataFrame(X.todense(), columns=columns)\n",
    "shoes_data_new_2 = pd.concat([shoes_data_new_2, c_v_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(product_description_prep)\n",
    "columns = ['product_description_' + str(i) for i in range(X.shape[1])]\n",
    "c_v_df = pd.DataFrame(X.todense(), columns=columns)\n",
    "shoes_data_new_2 = pd.concat([shoes_data_new_2, c_v_df], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –ü—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ –º–æ–¥–µ–ª–∏"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–°–Ω–∞—á–∞–ª–∞ —Å–¥–µ–ª–∞–µ–º –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—é. –î–ª—è —ç—Ç–æ–≥–æ —Ä–∞–∑–¥–µ–ª–∏–º —Ü–µ–Ω—ã –Ω–∞ –∫–ª–∞—Å—Å—ã."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "prices = list(shoes_data_new.price_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_class = [(i // 1000) for i in prices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "shoes_data_new['price_class'] = price_class\n",
    "shoes_data_new_2['price_class'] = price_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "del shoes_data_new['title_prep']\n",
    "del shoes_data_new_2['title_prep']\n",
    "del shoes_data_new['reviews_prep']\n",
    "del shoes_data_new_2['reviews_prep']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "del shoes_data_new['reviews_rating']\n",
    "del shoes_data_new_2['reviews_rating']\n",
    "del shoes_data_new['product_description_prep']\n",
    "del shoes_data_new_2['product_description_prep']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–í –∫–∞—á–µ—Å—Ç–≤–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –≤–æ–∑—å–º–µ–º:\n",
    "\n",
    "* –≤–µ–∫—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω–Ω—ã–µ –Ω–∞–∑–≤–∞–Ω–∏—è —Ç–æ–≤–∞—Ä–æ–≤\n",
    "* —Ä–µ–π—Ç–∏–Ω–≥–∏ —Ç–æ–≤–∞—Ä–æ–≤\n",
    "* –≤–µ–∫—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω–Ω—ã–µ –æ–ø–∏—Å–∞–Ω–∏—è —Ç–æ–≤–∞—Ä–æ–≤\n",
    "* –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ—Ç–∑—ã–≤–æ–≤ –Ω–∞ —Ç–æ–≤–∞—Ä—ã\n",
    "* —Ç–∏–ø –æ–±—É–≤–∏ (–º/–∂)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ù–∞—á–Ω–µ–º —Å –º–µ—Ç–æ–¥–∞ –±–ª–∏–∂–∞–π—à–µ–≥–æ —Å–æ—Å–µ–¥–∞ –Ω–∞ –¥–∞—Ç–∞—Å–µ—Ç–µ —Å –≤–µ–∫—Ç–æ—Ä–∞–º–∏ BoW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_columns = list(shoes_data_new.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = [col for col in all_columns if ('title_' in col) or ('product_description_' in col)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns.append('rating_new')\n",
    "feature_columns.append('shoe_type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(shoes_data_new[feature_columns], shoes_data_new.price_class,\n",
    "                                                    test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = KNeighborsClassifier().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc=0.5911\n",
      "micro F1=0.5911, micro P=0.5911, micro R=0.5911\n",
      "macro F1=0.4895, macro P=0.4385, macro R=0.6898\n",
      "\n"
     ]
    }
   ],
   "source": [
    "acc = accuracy_score(predicted, y_test)\n",
    "micro_f1 = f1_score(predicted, y_test, average = 'micro')\n",
    "micro_p = precision_score(predicted, y_test, average = 'micro')\n",
    "micro_r = recall_score(predicted, y_test, average = 'micro')\n",
    "macro_f1 = f1_score(predicted, y_test, average = 'macro')\n",
    "macro_p = precision_score(predicted, y_test, average = 'macro')\n",
    "macro_r = recall_score(predicted, y_test, average = 'macro')\n",
    "print('acc={0:1.4f}'.format(acc))\n",
    "print('micro F1={0:1.4f}, micro P={1:1.4f}, micro R={2:1.4f}'.format(micro_f1, micro_p, micro_r))\n",
    "print('macro F1={0:1.4f}, macro P={1:1.4f}, macro R={2:1.4f}\\n'.format(macro_f1, macro_p, macro_r))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–¢–µ–ø–µ—Ä—å –∫–∞—á–µ—Å—Ç–≤–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –≤–æ–∑—å–º–µ–º:\n",
    "\n",
    "* –≤–µ–∫—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω–Ω—ã–µ –Ω–∞–∑–≤–∞–Ω–∏—è —Ç–æ–≤–∞—Ä–æ–≤\n",
    "* —Ä–µ–π—Ç–∏–Ω–≥–∏ —Ç–æ–≤–∞—Ä–æ–≤\n",
    "* –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ—Ç–∑—ã–≤–æ–≤ –Ω–∞ —Ç–æ–≤–∞—Ä—ã\n",
    "* —Ç–∏–ø –æ–±—É–≤–∏ (–º/–∂)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc=0.6379\n",
      "micro F1=0.6379, micro P=0.6379, micro R=0.6379\n",
      "macro F1=0.4947, macro P=0.4766, macro R=0.6404\n",
      "\n"
     ]
    }
   ],
   "source": [
    "feature_columns = [col for col in all_columns if ('title_' in col)]\n",
    "feature_columns.append('rating_new')\n",
    "feature_columns.append('shoe_type')\n",
    "X_train, X_test, y_train, y_test = train_test_split(shoes_data_new[feature_columns], shoes_data_new.price_class,\n",
    "                                                    test_size=0.33, random_state=42)\n",
    "clf = KNeighborsClassifier().fit(X_train, y_train)\n",
    "predicted = clf.predict(X_test)\n",
    "acc = accuracy_score(predicted, y_test)\n",
    "micro_f1 = f1_score(predicted, y_test, average = 'micro')\n",
    "micro_p = precision_score(predicted, y_test, average = 'micro')\n",
    "micro_r = recall_score(predicted, y_test, average = 'micro')\n",
    "macro_f1 = f1_score(predicted, y_test, average = 'macro')\n",
    "macro_p = precision_score(predicted, y_test, average = 'macro')\n",
    "macro_r = recall_score(predicted, y_test, average = 'macro')\n",
    "print('acc={0:1.4f}'.format(acc))\n",
    "print('micro F1={0:1.4f}, micro P={1:1.4f}, micro R={2:1.4f}'.format(micro_f1, micro_p, micro_r))\n",
    "print('macro F1={0:1.4f}, macro P={1:1.4f}, macro R={2:1.4f}\\n'.format(macro_f1, macro_p, macro_r))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ö–∞–∫ –º—ã –≤–∏–¥–∏–º, –±–µ–∑ –æ–ø–∏—Å–∞–Ω–∏—è —Ç–æ–≤–∞—Ä–æ–≤ –º–æ–¥–µ–ª—å —Å—Ç–∞–ª–∞ —Ä–∞–±–æ—Ç–∞—Ç—å –ª—É—á—à–µ.\n",
    "\n",
    "–ü–æ—Å–º–æ—Ç—Ä–∏–º –Ω–∞ –∫–∞—á–µ—Å—Ç–≤–æ —Ä–∞–±–æ—Ç—ã –º–æ–¥–µ–ª–∏ —Å–æ —Å–ª–µ–¥—É—é—â–∏–º –Ω–∞–±–æ—Ä–æ–º –ø—Ä–∏–∑–Ω–∞–∫–æ–≤:\n",
    "\n",
    "* —Ä–µ–π—Ç–∏–Ω–≥–∏ —Ç–æ–≤–∞—Ä–æ–≤\n",
    "* –≤–µ–∫—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω–Ω—ã–µ –æ–ø–∏—Å–∞–Ω–∏—è —Ç–æ–≤–∞—Ä–æ–≤\n",
    "* –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ—Ç–∑—ã–≤–æ–≤ –Ω–∞ —Ç–æ–≤–∞—Ä—ã\n",
    "* —Ç–∏–ø –æ–±—É–≤–∏ (–º/–∂)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc=0.5837\n",
      "micro F1=0.5837, micro P=0.5837, micro R=0.5837\n",
      "macro F1=0.5040, macro P=0.4542, macro R=0.6714\n",
      "\n"
     ]
    }
   ],
   "source": [
    "feature_columns = [col for col in all_columns if ('product_description_' in col)]\n",
    "feature_columns.append('rating_new')\n",
    "feature_columns.append('shoe_type')\n",
    "X_train, X_test, y_train, y_test = train_test_split(shoes_data_new[feature_columns], shoes_data_new.price_class,\n",
    "                                                    test_size=0.33, random_state=42)\n",
    "clf = KNeighborsClassifier().fit(X_train, y_train)\n",
    "predicted = clf.predict(X_test)\n",
    "acc = accuracy_score(predicted, y_test)\n",
    "micro_f1 = f1_score(predicted, y_test, average = 'micro')\n",
    "micro_p = precision_score(predicted, y_test, average = 'micro')\n",
    "micro_r = recall_score(predicted, y_test, average = 'micro')\n",
    "macro_f1 = f1_score(predicted, y_test, average = 'macro')\n",
    "macro_p = precision_score(predicted, y_test, average = 'macro')\n",
    "macro_r = recall_score(predicted, y_test, average = 'macro')\n",
    "print('acc={0:1.4f}'.format(acc))\n",
    "print('micro F1={0:1.4f}, micro P={1:1.4f}, micro R={2:1.4f}'.format(micro_f1, micro_p, micro_r))\n",
    "print('macro F1={0:1.4f}, macro P={1:1.4f}, macro R={2:1.4f}\\n'.format(macro_f1, macro_p, macro_r))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ö–∞—á–µ—Å—Ç–≤–æ —Å—Ç–∞–ª–æ —Ö—É–∂–µ, —á—Ç–æ –∏ —Å–ª–µ–¥–æ–≤–∞–ª–æ –∏–∑ –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ü–æ–ø—Ä–æ–±—É–µ–º –º—É–ª—å—Ç–∏–Ω–æ–º–∏–∞–ª—å–Ω—ã–π –Ω–∞–∏–≤–Ω—ã–π –ë–∞–π—Å–æ–≤—Å–∫–∏–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä –Ω–∞ —Å–ª–µ–¥—É—é—â–µ–º –Ω–∞–±–æ—Ä–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (–ª—É—á—à–∏–π –Ω–∞–±–æ—Ä –∏–∑ –ø—Ä–æ—à–ª—ã—Ö, –¥–∞–ª–µ–µ —Ç–æ–∂–µ –±—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è –æ–Ω):\n",
    "* –≤–µ–∫—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω–Ω—ã–µ –Ω–∞–∑–≤–∞–Ω–∏—è —Ç–æ–≤–∞—Ä–æ–≤\n",
    "* —Ä–µ–π—Ç–∏–Ω–≥–∏ —Ç–æ–≤–∞—Ä–æ–≤\n",
    "* –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ—Ç–∑—ã–≤–æ–≤ –Ω–∞ —Ç–æ–≤–∞—Ä—ã\n",
    "* —Ç–∏–ø –æ–±—É–≤–∏ (–º/–∂)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc=0.6650\n",
      "micro F1=0.6650, micro P=0.6650, micro R=0.6650\n",
      "macro F1=0.4264, macro P=0.3878, macro R=0.6761\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "feature_columns = [col for col in all_columns if ('title_' in col)]\n",
    "feature_columns.append('rating_new')\n",
    "feature_columns.append('shoe_type')\n",
    "X_train, X_test, y_train, y_test = train_test_split(shoes_data_new[feature_columns], shoes_data_new.price_class,\n",
    "                                                    test_size=0.33, random_state=42)\n",
    "clf = MultinomialNB().fit(X_train, y_train)\n",
    "predicted = clf.predict(X_test)\n",
    "acc = accuracy_score(predicted, y_test)\n",
    "micro_f1 = f1_score(predicted, y_test, average = 'micro')\n",
    "micro_p = precision_score(predicted, y_test, average = 'micro')\n",
    "micro_r = recall_score(predicted, y_test, average = 'micro')\n",
    "macro_f1 = f1_score(predicted, y_test, average = 'macro')\n",
    "macro_p = precision_score(predicted, y_test, average = 'macro')\n",
    "macro_r = recall_score(predicted, y_test, average = 'macro')\n",
    "print('acc={0:1.4f}'.format(acc))\n",
    "print('micro F1={0:1.4f}, micro P={1:1.4f}, micro R={2:1.4f}'.format(micro_f1, micro_p, micro_r))\n",
    "print('macro F1={0:1.4f}, macro P={1:1.4f}, macro R={2:1.4f}\\n'.format(macro_f1, macro_p, macro_r))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ö–∞—á–µ—Å—Ç–≤–æ –Ω–µ–º–Ω–æ–≥–æ –≤—ã—à–µ, —á–µ–º —É –º–µ—Ç–æ–¥–∞ –±–ª–∏–∂–∞–π—à–∏—Ö —Å–æ—Å–µ–¥–µ–π"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ú–µ—Ç–æ–¥ –±–ª–∏–∂–∞–π—à–µ–≥–æ —Å–æ—Å–µ–¥–∞ –Ω–∞ –¥–∞—Ç–∞—Å–µ—Ç–µ —Å TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc=0.6576\n",
      "micro F1=0.6576, micro P=0.6576, micro R=0.6576\n",
      "macro F1=0.5042, macro P=0.4946, macro R=0.5701\n",
      "\n"
     ]
    }
   ],
   "source": [
    "feature_columns = [col for col in all_columns if ('title_' in col)]\n",
    "feature_columns.append('rating_new')\n",
    "feature_columns.append('shoe_type')\n",
    "X_train, X_test, y_train, y_test = train_test_split(shoes_data_new_2[feature_columns], shoes_data_new_2.price_class,\n",
    "                                                    test_size=0.33, random_state=42)\n",
    "clf = KNeighborsClassifier().fit(X_train, y_train)\n",
    "predicted = clf.predict(X_test)\n",
    "acc = accuracy_score(predicted, y_test)\n",
    "micro_f1 = f1_score(predicted, y_test, average = 'micro')\n",
    "micro_p = precision_score(predicted, y_test, average = 'micro')\n",
    "micro_r = recall_score(predicted, y_test, average = 'micro')\n",
    "macro_f1 = f1_score(predicted, y_test, average = 'macro')\n",
    "macro_p = precision_score(predicted, y_test, average = 'macro')\n",
    "macro_r = recall_score(predicted, y_test, average = 'macro')\n",
    "print('acc={0:1.4f}'.format(acc))\n",
    "print('micro F1={0:1.4f}, micro P={1:1.4f}, micro R={2:1.4f}'.format(micro_f1, micro_p, micro_r))\n",
    "print('macro F1={0:1.4f}, macro P={1:1.4f}, macro R={2:1.4f}\\n'.format(macro_f1, macro_p, macro_r))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ö–∞—á–µ—Å—Ç–≤–æ —Å—Ç–∞–ª–æ –ª—É—á—à–µ —Ç–æ–π –∂–µ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏, –Ω–æ —Å BoW, –Ω–æ –≤—Å–µ —Ä–∞–≤–Ω–æ —É—Å—Ç—É–ø–∞–µ—Ç –±–∞–π–µ—Å–æ–≤—Å–∫–æ–º—É –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä—É —Å BoW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ú—É–ª—å—Ç–∏–Ω–æ–º–∏–∞–ª—å–Ω—ã–π –Ω–∞–∏–≤–Ω—ã–π –ë–∞–π—Å–æ–≤—Å–∫–∏–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä c TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc=0.4828\n",
      "micro F1=0.4828, micro P=0.4828, micro R=0.4828\n",
      "macro F1=0.1389, macro P=0.1642, macro R=0.1848\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "feature_columns = [col for col in all_columns if ('title_' in col)]\n",
    "feature_columns.append('rating_new')\n",
    "feature_columns.append('shoe_type')\n",
    "X_train, X_test, y_train, y_test = train_test_split(shoes_data_new_2[feature_columns], shoes_data_new_2.price_class,\n",
    "                                                    test_size=0.33, random_state=42)\n",
    "clf = MultinomialNB().fit(X_train, y_train)\n",
    "predicted = clf.predict(X_test)\n",
    "acc = accuracy_score(predicted, y_test)\n",
    "micro_f1 = f1_score(predicted, y_test, average = 'micro')\n",
    "micro_p = precision_score(predicted, y_test, average = 'micro')\n",
    "micro_r = recall_score(predicted, y_test, average = 'micro')\n",
    "macro_f1 = f1_score(predicted, y_test, average = 'macro')\n",
    "macro_p = precision_score(predicted, y_test, average = 'macro')\n",
    "macro_r = recall_score(predicted, y_test, average = 'macro')\n",
    "print('acc={0:1.4f}'.format(acc))\n",
    "print('micro F1={0:1.4f}, micro P={1:1.4f}, micro R={2:1.4f}'.format(micro_f1, micro_p, micro_r))\n",
    "print('macro F1={0:1.4f}, macro P={1:1.4f}, macro R={2:1.4f}\\n'.format(macro_f1, macro_p, macro_r))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ö–∞—á–µ—Å—Ç–≤–æ —Å–∏–ª—å–Ω–æ —É–ø–∞–ª–æ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–¢–µ–ø–µ—Ä—å –ø–æ–ø—Ä–æ–±—É–µ–º –ª–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫—É—é —Ä–µ–≥—Ä–µ—Å—Å–∏—é –Ω–∞ BoW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc=0.7291\n",
      "micro F1=0.7291, micro P=0.7291, micro R=0.7291\n",
      "macro F1=0.6354, macro P=0.5906, macro R=0.7810\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "feature_columns = [col for col in all_columns if ('title_' in col)]\n",
    "feature_columns.append('rating_new')\n",
    "feature_columns.append('shoe_type')\n",
    "X_train, X_test, y_train, y_test = train_test_split(shoes_data_new[feature_columns], shoes_data_new.price_class,\n",
    "                                                    test_size=0.33, random_state=42)\n",
    "\n",
    "clf = LogisticRegression().fit(X_train, y_train)\n",
    "predicted = clf.predict(X_test)\n",
    "acc = accuracy_score(predicted, y_test)\n",
    "micro_f1 = f1_score(predicted, y_test, average = 'micro')\n",
    "micro_p = precision_score(predicted, y_test, average = 'micro')\n",
    "micro_r = recall_score(predicted, y_test, average = 'micro')\n",
    "macro_f1 = f1_score(predicted, y_test, average = 'macro')\n",
    "macro_p = precision_score(predicted, y_test, average = 'macro')\n",
    "macro_r = recall_score(predicted, y_test, average = 'macro')\n",
    "print('acc={0:1.4f}'.format(acc))\n",
    "print('micro F1={0:1.4f}, micro P={1:1.4f}, micro R={2:1.4f}'.format(micro_f1, micro_p, micro_r))\n",
    "print('macro F1={0:1.4f}, macro P={1:1.4f}, macro R={2:1.4f}\\n'.format(macro_f1, macro_p, macro_r))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ü–æ–ø—Ä–æ–±—É–µ–º –ª–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫—É—é —Ä–µ–≥—Ä–µ—Å—Å–∏—é –Ω–∞ TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc=0.7118\n",
      "micro F1=0.7118, micro P=0.7118, micro R=0.7118\n",
      "macro F1=0.6038, macro P=0.5390, macro R=0.8262\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "feature_columns = [col for col in all_columns if ('title_' in col)]\n",
    "feature_columns.append('rating_new')\n",
    "feature_columns.append('shoe_type')\n",
    "X_train, X_test, y_train, y_test = train_test_split(shoes_data_new_2[feature_columns], shoes_data_new_2.price_class,\n",
    "                                                    test_size=0.33, random_state=42)\n",
    "\n",
    "clf = LogisticRegression().fit(X_train, y_train)\n",
    "predicted = clf.predict(X_test)\n",
    "acc = accuracy_score(predicted, y_test)\n",
    "micro_f1 = f1_score(predicted, y_test, average = 'micro')\n",
    "micro_p = precision_score(predicted, y_test, average = 'micro')\n",
    "micro_r = recall_score(predicted, y_test, average = 'micro')\n",
    "macro_f1 = f1_score(predicted, y_test, average = 'macro')\n",
    "macro_p = precision_score(predicted, y_test, average = 'macro')\n",
    "macro_r = recall_score(predicted, y_test, average = 'macro')\n",
    "print('acc={0:1.4f}'.format(acc))\n",
    "print('micro F1={0:1.4f}, micro P={1:1.4f}, micro R={2:1.4f}'.format(micro_f1, micro_p, micro_r))\n",
    "print('macro F1={0:1.4f}, macro P={1:1.4f}, macro R={2:1.4f}\\n'.format(macro_f1, macro_p, macro_r))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ü–æ–ø—Ä–æ–±—É–µ–º –º–µ—Ç–æ–¥ –æ–ø–æ—Ä–Ω—ã—Ö –≤–µ–∫—Ç–æ—Ä–æ–≤"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–°–Ω–∞—á–∞–ª–∞ —Å BoW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc=0.7291\n",
      "micro F1=0.7291, micro P=0.7291, micro R=0.7291\n",
      "macro F1=0.6430, macro P=0.6080, macro R=0.7405\n",
      "\n"
     ]
    }
   ],
   "source": [
    "feature_columns = [col for col in all_columns if ('title_' in col)]\n",
    "feature_columns.append('rating_new')\n",
    "feature_columns.append('shoe_type')\n",
    "X_train, X_test, y_train, y_test = train_test_split(shoes_data_new[feature_columns], shoes_data_new.price_class,\n",
    "                                                    test_size=0.33, random_state=42)\n",
    "\n",
    "clf = LinearSVC().fit(X_train, y_train)\n",
    "predicted = clf.predict(X_test)\n",
    "acc = accuracy_score(predicted, y_test)\n",
    "micro_f1 = f1_score(predicted, y_test, average = 'micro')\n",
    "micro_p = precision_score(predicted, y_test, average = 'micro')\n",
    "micro_r = recall_score(predicted, y_test, average = 'micro')\n",
    "macro_f1 = f1_score(predicted, y_test, average = 'macro')\n",
    "macro_p = precision_score(predicted, y_test, average = 'macro')\n",
    "macro_r = recall_score(predicted, y_test, average = 'macro')\n",
    "print('acc={0:1.4f}'.format(acc))\n",
    "print('micro F1={0:1.4f}, micro P={1:1.4f}, micro R={2:1.4f}'.format(micro_f1, micro_p, micro_r))\n",
    "print('macro F1={0:1.4f}, macro P={1:1.4f}, macro R={2:1.4f}\\n'.format(macro_f1, macro_p, macro_r))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–¢–µ–ø–µ—Ä—å —Å TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc=0.7414\n",
      "micro F1=0.7414, micro P=0.7414, micro R=0.7414\n",
      "macro F1=0.6498, macro P=0.6091, macro R=0.7264\n",
      "\n"
     ]
    }
   ],
   "source": [
    "feature_columns = [col for col in all_columns if ('title_' in col)]\n",
    "feature_columns.append('rating_new')\n",
    "feature_columns.append('shoe_type')\n",
    "X_train, X_test, y_train, y_test = train_test_split(shoes_data_new_2[feature_columns], shoes_data_new_2.price_class,\n",
    "                                                    test_size=0.33, random_state=42)\n",
    "\n",
    "clf = LinearSVC().fit(X_train, y_train)\n",
    "predicted = clf.predict(X_test)\n",
    "acc = accuracy_score(predicted, y_test)\n",
    "micro_f1 = f1_score(predicted, y_test, average = 'micro')\n",
    "micro_p = precision_score(predicted, y_test, average = 'micro')\n",
    "micro_r = recall_score(predicted, y_test, average = 'micro')\n",
    "macro_f1 = f1_score(predicted, y_test, average = 'macro')\n",
    "macro_p = precision_score(predicted, y_test, average = 'macro')\n",
    "macro_r = recall_score(predicted, y_test, average = 'macro')\n",
    "print('acc={0:1.4f}'.format(acc))\n",
    "print('micro F1={0:1.4f}, micro P={1:1.4f}, micro R={2:1.4f}'.format(micro_f1, micro_p, micro_r))\n",
    "print('macro F1={0:1.4f}, macro P={1:1.4f}, macro R={2:1.4f}\\n'.format(macro_f1, macro_p, macro_r))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–î–µ—Ä–µ–≤—å—è —Ä–µ—à–µ–Ω–∏–π —Å BoW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc=0.7094\n",
      "micro F1=0.7094, micro P=0.7094, micro R=0.7094\n",
      "macro F1=0.6048, macro P=0.5729, macro R=0.7029\n",
      "\n"
     ]
    }
   ],
   "source": [
    "feature_columns = [col for col in all_columns if ('title_' in col)]\n",
    "feature_columns.append('rating_new')\n",
    "feature_columns.append('shoe_type')\n",
    "X_train, X_test, y_train, y_test = train_test_split(shoes_data_new[feature_columns], shoes_data_new.price_class,\n",
    "                                                    test_size=0.33, random_state=42)\n",
    "\n",
    "clf = DecisionTreeClassifier().fit(X_train, y_train)\n",
    "predicted = clf.predict(X_test)\n",
    "acc = accuracy_score(predicted, y_test)\n",
    "micro_f1 = f1_score(predicted, y_test, average = 'micro')\n",
    "micro_p = precision_score(predicted, y_test, average = 'micro')\n",
    "micro_r = recall_score(predicted, y_test, average = 'micro')\n",
    "macro_f1 = f1_score(predicted, y_test, average = 'macro')\n",
    "macro_p = precision_score(predicted, y_test, average = 'macro')\n",
    "macro_r = recall_score(predicted, y_test, average = 'macro')\n",
    "print('acc={0:1.4f}'.format(acc))\n",
    "print('micro F1={0:1.4f}, micro P={1:1.4f}, micro R={2:1.4f}'.format(micro_f1, micro_p, micro_r))\n",
    "print('macro F1={0:1.4f}, macro P={1:1.4f}, macro R={2:1.4f}\\n'.format(macro_f1, macro_p, macro_r))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–î–µ—Ä–µ–≤—å—è —Ä–µ—à–µ–Ω–∏–π —Å TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc=0.7143\n",
      "micro F1=0.7143, micro P=0.7143, micro R=0.7143\n",
      "macro F1=0.6523, macro P=0.6209, macro R=0.6947\n",
      "\n"
     ]
    }
   ],
   "source": [
    "feature_columns = [col for col in all_columns if ('title_' in col)]\n",
    "feature_columns.append('rating_new')\n",
    "feature_columns.append('shoe_type')\n",
    "X_train, X_test, y_train, y_test = train_test_split(shoes_data_new_2[feature_columns], shoes_data_new_2.price_class,\n",
    "                                                    test_size=0.33, random_state=42)\n",
    "\n",
    "clf = DecisionTreeClassifier().fit(X_train, y_train)\n",
    "predicted = clf.predict(X_test)\n",
    "acc = accuracy_score(predicted, y_test)\n",
    "micro_f1 = f1_score(predicted, y_test, average = 'micro')\n",
    "micro_p = precision_score(predicted, y_test, average = 'micro')\n",
    "micro_r = recall_score(predicted, y_test, average = 'micro')\n",
    "macro_f1 = f1_score(predicted, y_test, average = 'macro')\n",
    "macro_p = precision_score(predicted, y_test, average = 'macro')\n",
    "macro_r = recall_score(predicted, y_test, average = 'macro')\n",
    "print('acc={0:1.4f}'.format(acc))\n",
    "print('micro F1={0:1.4f}, micro P={1:1.4f}, micro R={2:1.4f}'.format(micro_f1, micro_p, micro_r))\n",
    "print('macro F1={0:1.4f}, macro P={1:1.4f}, macro R={2:1.4f}\\n'.format(macro_f1, macro_p, macro_r))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lasso c BoW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean absolute error =  829.9509370922685\n"
     ]
    }
   ],
   "source": [
    "feature_columns = [col for col in all_columns if ('title_' in col)]\n",
    "feature_columns.append('rating_new')\n",
    "feature_columns.append('shoe_type')\n",
    "X_train, X_test, y_train, y_test = train_test_split(shoes_data_new[feature_columns], shoes_data_new.price_new,\n",
    "                                                    test_size=0.33, random_state=42)\n",
    "\n",
    "clf = Lasso(alpha=10).fit(X_train, y_train)\n",
    "predicted = clf.predict(X_test)\n",
    "m = mean_absolute_error(y_test, predicted)\n",
    "print('mean absolute error = ', m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lasso —Å TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean absolute error =  1002.1411283227577\n"
     ]
    }
   ],
   "source": [
    "feature_columns = [col for col in all_columns if ('title_' in col)]\n",
    "feature_columns.append('rating_new')\n",
    "feature_columns.append('shoe_type')\n",
    "X_train, X_test, y_train, y_test = train_test_split(shoes_data_new_2[feature_columns], shoes_data_new_2.price_new,\n",
    "                                                    test_size=0.33, random_state=42)\n",
    "\n",
    "clf = Lasso(alpha=10).fit(X_train, y_train)\n",
    "predicted = clf.predict(X_test)\n",
    "m = mean_absolute_error(y_test, predicted)\n",
    "print('mean absolute error = ', m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ridge —Å BoW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean absolute error =  574.5742473888711\n"
     ]
    }
   ],
   "source": [
    "feature_columns = [col for col in all_columns if ('title_' in col)]\n",
    "feature_columns.append('rating_new')\n",
    "feature_columns.append('shoe_type')\n",
    "X_train, X_test, y_train, y_test = train_test_split(shoes_data_new[feature_columns], shoes_data_new.price_new,\n",
    "                                                    test_size=0.33, random_state=42)\n",
    "\n",
    "clf = Ridge().fit(X_train, y_train)\n",
    "predicted = clf.predict(X_test)\n",
    "m = mean_absolute_error(y_test, predicted)\n",
    "print('mean absolute error = ', m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ridge —Å TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean absolute error =  691.3383518555916\n"
     ]
    }
   ],
   "source": [
    "feature_columns = [col for col in all_columns if ('title_' in col)]\n",
    "feature_columns.append('rating_new')\n",
    "feature_columns.append('shoe_type')\n",
    "X_train, X_test, y_train, y_test = train_test_split(shoes_data_new_2[feature_columns], shoes_data_new_2.price_new,\n",
    "                                                    test_size=0.33, random_state=42)\n",
    "\n",
    "clf = Ridge().fit(X_train, y_train)\n",
    "predicted = clf.predict(X_test)\n",
    "m = mean_absolute_error(y_test, predicted)\n",
    "print('mean absolute error = ', m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LinearSVR —Å BoW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean absolute error =  1187.3246640197149\n"
     ]
    }
   ],
   "source": [
    "feature_columns = [col for col in all_columns if ('title_' in col)]\n",
    "feature_columns.append('rating_new')\n",
    "feature_columns.append('shoe_type')\n",
    "X_train, X_test, y_train, y_test = train_test_split(shoes_data_new[feature_columns], shoes_data_new.price_new,\n",
    "                                                    test_size=0.33, random_state=42)\n",
    "\n",
    "clf = LinearSVR(C=1).fit(X_train, y_train)\n",
    "predicted = clf.predict(X_test)\n",
    "m = mean_absolute_error(y_test, predicted)\n",
    "print('mean absolute error = ', m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LinearSVR c TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean absolute error =  1214.894758919063\n"
     ]
    }
   ],
   "source": [
    "feature_columns = [col for col in all_columns if ('title_' in col)]\n",
    "feature_columns.append('rating_new')\n",
    "feature_columns.append('shoe_type')\n",
    "X_train, X_test, y_train, y_test = train_test_split(shoes_data_new_2[feature_columns], shoes_data_new_2.price_new,\n",
    "                                                    test_size=0.33, random_state=42)\n",
    "\n",
    "clf = LinearSVR(C=1).fit(X_train, y_train)\n",
    "predicted = clf.predict(X_test)\n",
    "m = mean_absolute_error(y_test, predicted)\n",
    "print('mean absolute error = ', m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –õ—É—á—à–∞—è –º–æ–¥–µ–ª—å –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ - SVM –Ω–∞ —Å–ª–µ–¥—É—é—â–µ–º –Ω–∞–±–æ—Ä–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤:\n",
    "* –≤–µ–∫—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω–Ω—ã–µ –Ω–∞–∑–≤–∞–Ω–∏—è —Ç–æ–≤–∞—Ä–æ–≤ (TFIDF)\n",
    "* —Ä–µ–π—Ç–∏–Ω–≥–∏ —Ç–æ–≤–∞—Ä–æ–≤\n",
    "* –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ—Ç–∑—ã–≤–æ–≤ –Ω–∞ —Ç–æ–≤–∞—Ä—ã\n",
    "* —Ç–∏–ø –æ–±—É–≤–∏ (–º/–∂)\n",
    "\n",
    "### –ü–æ–ø—Ä–æ–±—É–µ–º –ø—Ä–∏–º–µ–Ω–∏—Ç—å –∫ –Ω–µ–π –≥—Ä–∏–¥—Å–µ—Ä—á"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 966, in _fit_liblinear\n",
      "    raw_coef_, n_iter_ = liblinear.train_wrap(\n",
      "  File \"sklearn/svm/_liblinear.pyx\", line 52, in sklearn.svm._liblinear.train_wrap\n",
      "ValueError: b'C <= 0'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 966, in _fit_liblinear\n",
      "    raw_coef_, n_iter_ = liblinear.train_wrap(\n",
      "  File \"sklearn/svm/_liblinear.pyx\", line 52, in sklearn.svm._liblinear.train_wrap\n",
      "ValueError: b'C <= 0'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 966, in _fit_liblinear\n",
      "    raw_coef_, n_iter_ = liblinear.train_wrap(\n",
      "  File \"sklearn/svm/_liblinear.pyx\", line 52, in sklearn.svm._liblinear.train_wrap\n",
      "ValueError: b'C <= 0'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 966, in _fit_liblinear\n",
      "    raw_coef_, n_iter_ = liblinear.train_wrap(\n",
      "  File \"sklearn/svm/_liblinear.pyx\", line 52, in sklearn.svm._liblinear.train_wrap\n",
      "ValueError: b'C <= 0'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 966, in _fit_liblinear\n",
      "    raw_coef_, n_iter_ = liblinear.train_wrap(\n",
      "  File \"sklearn/svm/_liblinear.pyx\", line 52, in sklearn.svm._liblinear.train_wrap\n",
      "ValueError: b'C <= 0'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 966, in _fit_liblinear\n",
      "    raw_coef_, n_iter_ = liblinear.train_wrap(\n",
      "  File \"sklearn/svm/_liblinear.pyx\", line 52, in sklearn.svm._liblinear.train_wrap\n",
      "ValueError: b'C <= 0'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 966, in _fit_liblinear\n",
      "    raw_coef_, n_iter_ = liblinear.train_wrap(\n",
      "  File \"sklearn/svm/_liblinear.pyx\", line 52, in sklearn.svm._liblinear.train_wrap\n",
      "ValueError: b'C <= 0'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 966, in _fit_liblinear\n",
      "    raw_coef_, n_iter_ = liblinear.train_wrap(\n",
      "  File \"sklearn/svm/_liblinear.pyx\", line 52, in sklearn.svm._liblinear.train_wrap\n",
      "ValueError: b'C <= 0'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 966, in _fit_liblinear\n",
      "    raw_coef_, n_iter_ = liblinear.train_wrap(\n",
      "  File \"sklearn/svm/_liblinear.pyx\", line 52, in sklearn.svm._liblinear.train_wrap\n",
      "ValueError: b'C <= 0'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 966, in _fit_liblinear\n",
      "    raw_coef_, n_iter_ = liblinear.train_wrap(\n",
      "  File \"sklearn/svm/_liblinear.pyx\", line 52, in sklearn.svm._liblinear.train_wrap\n",
      "ValueError: b'C <= 0'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=LinearSVC(),\n",
       "             param_grid={'C': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
       "                         'loss': ('hinge', 'squared_hinge'),\n",
       "                         'penalty': ('l1', 'l2')},\n",
       "             scoring=make_scorer(accuracy_score))"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_columns = [col for col in all_columns if ('title_' in col)]\n",
    "feature_columns.append('rating_new')\n",
    "feature_columns.append('shoe_type')\n",
    "X_train, X_test, y_train, y_test = train_test_split(shoes_data_new_2[feature_columns], shoes_data_new_2.price_class,\n",
    "                                                    test_size=0.33, random_state=42)\n",
    "parameters = {'penalty':('l1', 'l2'), 'loss':('hinge', 'squared_hinge'), 'C':[i for i in range(10)]}\n",
    "svc = LinearSVC()\n",
    "scorer = make_scorer(accuracy_score)\n",
    "clf = GridSearchCV(estimator=svc, param_grid=parameters, scoring=scorer)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–õ—É—á—à–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤: \n",
      "{'C': 1, 'loss': 'squared_hinge', 'penalty': 'l2'}\n",
      "–ó–Ω–∞—á–µ–Ω–∏—è –º–µ—Ç—Ä–∏–∫ –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ 1214.894758919063\n",
      "acc=0.7414\n",
      "micro F1=0.7414, micro P=0.7414, micro R=0.7414\n",
      "macro F1=0.6498, macro P=0.6091, macro R=0.7264\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('–õ—É—á—à–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤: ')\n",
    "print(clf.best_params_)\n",
    "predicted = clf.predict(X_test)\n",
    "print('–ó–Ω–∞—á–µ–Ω–∏—è –º–µ—Ç—Ä–∏–∫ –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ', m)\n",
    "predicted = clf.predict(X_test)\n",
    "acc = accuracy_score(predicted, y_test)\n",
    "micro_f1 = f1_score(predicted, y_test, average = 'micro')\n",
    "micro_p = precision_score(predicted, y_test, average = 'micro')\n",
    "micro_r = recall_score(predicted, y_test, average = 'micro')\n",
    "macro_f1 = f1_score(predicted, y_test, average = 'macro')\n",
    "macro_p = precision_score(predicted, y_test, average = 'macro')\n",
    "macro_r = recall_score(predicted, y_test, average = 'macro')\n",
    "print('acc={0:1.4f}'.format(acc))\n",
    "print('micro F1={0:1.4f}, micro P={1:1.4f}, micro R={2:1.4f}'.format(micro_f1, micro_p, micro_r))\n",
    "print('macro F1={0:1.4f}, macro P={1:1.4f}, macro R={2:1.4f}\\n'.format(macro_f1, macro_p, macro_r))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–õ—É—á—à–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ –æ—Å—Ç–∞–ª–æ—Å—å –ø—Ä–µ–∂–Ω–∏–º."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = [0, 1, 2, 3, 4, 5, 6, 7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(data=confusion_matrix(y_test, predicted), annot=True, fmt=\"d\", cbar=False, xticklabels=categories, yticklabels=categories)\n",
    "plt.title(\"Confusion matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* –ö–∞–∫ –º—ã –≤–∏–¥–∏–º, –º–æ–¥–µ–ª—å —Ö–æ—Ä–æ—à–æ —Å–ø—Ä–∞–≤–ª—è–µ—Ç—Å—è —Å —Ç–æ–≤–∞—Ä–∞–º–∏, —Å—Ç–æ–∏–º–æ—Å—Ç—å –∫–æ—Ç–æ—Ä—ã—Ö –Ω–µ –ø—Ä–∏–≤—ã—à–∞–µ—Ç 1000 —Ä—É–ø–∏–π\n",
    "* –¢–∞–∫–∂–µ –º–æ–¥–µ–ª—å —Ö–æ—Ä–æ—à–æ —Å–ø—Ä–∞–≤–ª—è–µ—Ç—Å—è —Å —Ç–æ–≤–∞—Ä–∞–º–∏ —Å—Ç–æ–∏–º–æ—Å—Ç—å—é –æ—Ç 1 –¥–æ 2 —Ç—ã—Å. —Ä—É–ø–∏–π, –Ω–æ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —á–∞—Å—Ç–æ –æ—à–∏–±–æ—á–Ω–æ –æ—Ç–Ω–æ—Å–∏—Ç —Ç–æ–≤–∞—Ä—ã –∏–∑ —ç—Ç–æ–π —Ü–µ–Ω–æ–≤–æ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –∫ —Ç–æ–≤–∞—Ä–∞–º, –∫–æ—Ç–æ—Ä—ã–µ —Å—Ç–æ—è—Ç 2-3 —Ç—ã—á. —Ä—É–ø–∏–π\n",
    "* –í –¥–≤—É—Ö –∏–∑ —á–µ—Ç—ã—Ä–µ—Ö —Å–ª—É—á–∞—è—Ö –º–æ–¥–µ–ª—å –æ—à–∏–±–∞–µ—Ç—Å—è —Å —Ç–æ–≤–∞—Ä–∞–º–∏, –∫–æ—Ç–æ—Ä—ã–µ —Å—Ç–æ—è—Ç 6-7 —Ç—ã—Å. —Ä—É–ø–∏–π\n",
    "* –í –æ—Å—Ç–∞–ª—å–Ω—ã—Ö —Å–ª—É—á–∞—è—Ö –º–æ–¥–µ–ª—å –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –Ω–æ—Ä–º–∞–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã: –±–û–ª—å—à–∞—è —á–∞—Å—Ç—å –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∞ –ø–æ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º –∫–ª–∞—Å—Å–∞–º, –∏ –º–µ–Ω—å—à–∞—è - –ø–æ –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–º"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –õ—É—á—à–∞—è –º–æ–¥–µ–ª—å —Ä–µ–≥—Ä–µ—Å—Å–∏ - Ridge —Å–æ —Å–ª–µ–¥—É—é—â–∏–º –Ω–∞–±–æ—Ä–æ–º –ø—Ä–∏–∑–Ω–∞–∫–æ–≤:\n",
    "\n",
    "* –≤–µ–∫—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω–Ω—ã–µ –Ω–∞–∑–≤–∞–Ω–∏—è —Ç–æ–≤–∞—Ä–æ–≤ (BoW)\n",
    "* —Ä–µ–π—Ç–∏–Ω–≥–∏ —Ç–æ–≤–∞—Ä–æ–≤\n",
    "* –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ—Ç–∑—ã–≤–æ–≤ –Ω–∞ —Ç–æ–≤–∞—Ä—ã\n",
    "* —Ç–∏–ø –æ–±—É–≤–∏ (–º/–∂)\n",
    "\n",
    "### –ü–æ–ø—Ä–æ–±—É–µ–º –ø—Ä–∏–º–µ–Ω–∏—Ç—å –∫ –Ω–µ–π –≥—Ä–∏–¥—Å–µ—Ä—á"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:190: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n",
      "  warnings.warn(\"Singular matrix in solving dual problem. Using \"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:190: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n",
      "  warnings.warn(\"Singular matrix in solving dual problem. Using \"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:190: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n",
      "  warnings.warn(\"Singular matrix in solving dual problem. Using \"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:190: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n",
      "  warnings.warn(\"Singular matrix in solving dual problem. Using \"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:190: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n",
      "  warnings.warn(\"Singular matrix in solving dual problem. Using \"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:190: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n",
      "  warnings.warn(\"Singular matrix in solving dual problem. Using \"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:190: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n",
      "  warnings.warn(\"Singular matrix in solving dual problem. Using \"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:190: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n",
      "  warnings.warn(\"Singular matrix in solving dual problem. Using \"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:190: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n",
      "  warnings.warn(\"Singular matrix in solving dual problem. Using \"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:190: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n",
      "  warnings.warn(\"Singular matrix in solving dual problem. Using \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Ridge(),\n",
       "             param_grid={'alpha': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
       "                         'solver': ['auto', 'svd', 'cholesky', 'lsqr',\n",
       "                                    'sparse_cg', 'sag', 'saga']},\n",
       "             scoring=make_scorer(mean_absolute_error, greater_is_better=False))"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_columns = [col for col in all_columns if ('title_' in col)]\n",
    "feature_columns.append('rating_new')\n",
    "feature_columns.append('shoe_type')\n",
    "X_train, X_test, y_train, y_test = train_test_split(shoes_data_new[feature_columns], shoes_data_new.price_new,\n",
    "                                                    test_size=0.33, random_state=42)\n",
    "parameters = {'alpha':[i for i in range(11)], 'solver': ['auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg',\n",
    "                                                         'sag', 'saga']}\n",
    "reg = Ridge()\n",
    "scorer = make_scorer(mean_absolute_error, greater_is_better=False)\n",
    "clf = GridSearchCV(estimator=reg,param_grid=parameters, scoring=scorer)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–õ—É—á—à–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤: \n",
      "{'alpha': 0, 'solver': 'saga'}\n",
      "mean absolute error –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ =  549.6824633868761\n"
     ]
    }
   ],
   "source": [
    "print('–õ—É—á—à–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤: ')\n",
    "print(clf.best_params_)\n",
    "predicted = clf.predict(X_test)\n",
    "m = mean_absolute_error(y_test, predicted)\n",
    "print('mean absolute error –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ = ', m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–° –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–º–∏ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ –∑–Ω–∞—á–µ–Ω–∏–µ —Å—Ä–µ–¥–Ω–µ–π –æ—à–∏–±–∫–∏ —É–º–µ–Ω—å—à–∏–ª–æ—Å—å –Ω–∞ 20 —Ä—É–ø–∏–π."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=0, solver='saga')"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_columns = [col for col in all_columns if ('title_' in col)]\n",
    "feature_columns.append('rating_new')\n",
    "feature_columns.append('shoe_type')\n",
    "X_train, X_test, y_train, y_test = train_test_split(shoes_data_new[feature_columns], shoes_data_new.price_new,\n",
    "                                                    test_size=0.33, random_state=42)\n",
    "parameters = {'alpha':[i for i in range(11)], 'solver': ['auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg',\n",
    "                                                         'sag', 'saga']}\n",
    "\n",
    "reg = Ridge(alpha=0, solver='saga')\n",
    "reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ü–æ—Å–º–æ—Ç—Ä–∏–º –Ω–∞ –≤–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def importances(model, feature_columns):\n",
    "    l1 = sorted(list(zip(list(model.coef_), feature_columns)), reverse=True)\n",
    "    l2 = []\n",
    "    counter_1 = 0\n",
    "    counter_2 = 0\n",
    "    counter_3 = 0\n",
    "    for i in l1:\n",
    "        if 'title_' in i[1]:\n",
    "            counter_1 += i[0]\n",
    "        elif 'reviews_' in i[1]:\n",
    "            counter_2 += i[0]\n",
    "        elif 'product_description_' in i[1]:\n",
    "            counter_3 += i[0]\n",
    "        else:\n",
    "            l2.append(i)\n",
    "            \n",
    "    \n",
    "    if counter_1 != 0:\n",
    "        l2.append((counter_1, 'title_embeddings'))\n",
    "        \n",
    "    if counter_2 != 0:\n",
    "        l2.append((counter_2, 'reviews_embeddings'))\n",
    "        \n",
    "    if counter_3 != 0:\n",
    "        l2.append((counter_3, 'product_description_embeddings'))    \n",
    "        \n",
    "    print(sorted(l2, reverse=True))\n",
    "    plt.bar([l[1] for l in l2], [l[0] for l in l2])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(43000.108778324975, 'title_embeddings'), (1131.1506413930792, 'shoe_type'), (-30.21544764715223, 'rating_new')]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "importances(reg, feature_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ö–∞–∫ –º—ã –≤–∏–¥–∏–º, –Ω–∞–ª–∏—á–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∞ —Ä–µ–π—Ç–∏–Ω–≥–∞ —Ç–æ–≤–∞—Ä–æ–≤ –Ω–µ –≤–ª–∏—è–µ—Ç –Ω–∞ —Ä–∞–±–æ—Ç—É –º–æ–¥–µ–ª–∏, –∞ –≤–∏–¥ –æ–±—É–≤–∏ (–º/–∂) –∏–º–µ–µ—Ç —Å–æ–≤—Å–µ–º –º–∞–ª–µ–Ω—å–∫–æ–µ –≤–ª–∏—è–Ω–∏–µ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2798.70965589, 2924.19658507,  712.45275215, 2594.16839302,\n",
       "       6119.88602916, 2518.04979275,  556.85116688, 2798.70965589,\n",
       "        672.1617313 ,  756.62254215, 1856.77857909,  620.32888636,\n",
       "        698.94955486, 3801.32294097, 3522.16340076, 2345.03322262,\n",
       "        752.41690108,  812.95827768,  837.20414374, 2798.70965589])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "548     2941.0\n",
       "704     3599.0\n",
       "244      569.0\n",
       "552     2050.0\n",
       "1164    6126.0\n",
       "1049    2449.0\n",
       "901      379.0\n",
       "589     1273.0\n",
       "101      349.0\n",
       "128      299.0\n",
       "420     1049.0\n",
       "977      599.0\n",
       "210      729.0\n",
       "1092    3779.0\n",
       "541     2186.0\n",
       "415     1574.0\n",
       "869      598.0\n",
       "365      836.0\n",
       "899      374.0\n",
       "328     1509.0\n",
       "Name: price_new, dtype: float64"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>price</th>\n",
       "      <th>rating</th>\n",
       "      <th>total_reviews</th>\n",
       "      <th>product_description</th>\n",
       "      <th>reviews</th>\n",
       "      <th>reviews_rating</th>\n",
       "      <th>Shoe Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>550</th>\n",
       "      <td>Skechers Men Go 600 Running Shoes</td>\n",
       "      <td>‚Çπ2474.00</td>\n",
       "      <td>4.3 out of 5 stars</td>\n",
       "      <td>235 ratings</td>\n",
       "      <td>Upper: Strong yet soft dual-tone textured knit...</td>\n",
       "      <td>Excellent light weight stylish shoes grip and ...</td>\n",
       "      <td>5.0 out of 5 stars|| 3.0 out of 5 stars|| 2.0 ...</td>\n",
       "      <td>Men</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551</th>\n",
       "      <td>Skechers Men's Go Run Tr-Torch Shoes</td>\n",
       "      <td>‚Çπ2250.00</td>\n",
       "      <td>4.2 out of 5 stars</td>\n",
       "      <td>385 ratings</td>\n",
       "      <td>Skechers footwear with comfort and style.</td>\n",
       "      <td>Product is too good|| It's a perfect piece of ...</td>\n",
       "      <td>5.0 out of 5 stars|| 4.0 out of 5 stars|| 4.0 ...</td>\n",
       "      <td>Men</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>552</th>\n",
       "      <td>Adidas Men Running Shoes</td>\n",
       "      <td>‚Çπ2050.00</td>\n",
       "      <td>4.4 out of 5 stars</td>\n",
       "      <td>3 ratings</td>\n",
       "      <td>Adidas is the world's leading manufacturer of ...</td>\n",
       "      <td>Adidas the best|| Impressive prroduct</td>\n",
       "      <td>5.0 out of 5 stars|| 4.0 out of 5 stars</td>\n",
       "      <td>Men</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>553</th>\n",
       "      <td>Hush Puppies Men Elgar Oxford Leather Formal S...</td>\n",
       "      <td>‚Çπ3644.00</td>\n",
       "      <td>4.0 out of 5 stars</td>\n",
       "      <td>137 ratings</td>\n",
       "      <td>Experience great comfort walking in this pair ...</td>\n",
       "      <td>Good product from Hush puppies|| Very comforta...</td>\n",
       "      <td>5.0 out of 5 stars|| 5.0 out of 5 stars|| 4.0 ...</td>\n",
       "      <td>Men</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>New Balance Men's Fresh Foam Roav v1 Running Shoe</td>\n",
       "      <td>‚Çπ2942.00</td>\n",
       "      <td>4.6 out of 5 stars</td>\n",
       "      <td>251 ratings</td>\n",
       "      <td>Designed for athletes on-the-go the New Balanc...</td>\n",
       "      <td>Report abuse|| Report abuse|| Verified Purchas...</td>\n",
       "      <td>5.0 out of 5 stars|| 3.0 out of 5 stars|| 5.0 ...</td>\n",
       "      <td>Men</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title     price  \\\n",
       "550                  Skechers Men Go 600 Running Shoes  ‚Çπ2474.00   \n",
       "551               Skechers Men's Go Run Tr-Torch Shoes  ‚Çπ2250.00   \n",
       "552                           Adidas Men Running Shoes  ‚Çπ2050.00   \n",
       "553  Hush Puppies Men Elgar Oxford Leather Formal S...  ‚Çπ3644.00   \n",
       "554  New Balance Men's Fresh Foam Roav v1 Running Shoe  ‚Çπ2942.00   \n",
       "\n",
       "                 rating total_reviews  \\\n",
       "550  4.3 out of 5 stars   235 ratings   \n",
       "551  4.2 out of 5 stars   385 ratings   \n",
       "552  4.4 out of 5 stars     3 ratings   \n",
       "553  4.0 out of 5 stars   137 ratings   \n",
       "554  4.6 out of 5 stars   251 ratings   \n",
       "\n",
       "                                   product_description  \\\n",
       "550  Upper: Strong yet soft dual-tone textured knit...   \n",
       "551          Skechers footwear with comfort and style.   \n",
       "552  Adidas is the world's leading manufacturer of ...   \n",
       "553  Experience great comfort walking in this pair ...   \n",
       "554  Designed for athletes on-the-go the New Balanc...   \n",
       "\n",
       "                                               reviews  \\\n",
       "550  Excellent light weight stylish shoes grip and ...   \n",
       "551  Product is too good|| It's a perfect piece of ...   \n",
       "552              Adidas the best|| Impressive prroduct   \n",
       "553  Good product from Hush puppies|| Very comforta...   \n",
       "554  Report abuse|| Report abuse|| Verified Purchas...   \n",
       "\n",
       "                                        reviews_rating Shoe Type  \n",
       "550  5.0 out of 5 stars|| 3.0 out of 5 stars|| 2.0 ...       Men  \n",
       "551  5.0 out of 5 stars|| 4.0 out of 5 stars|| 4.0 ...       Men  \n",
       "552            5.0 out of 5 stars|| 4.0 out of 5 stars       Men  \n",
       "553  5.0 out of 5 stars|| 5.0 out of 5 stars|| 4.0 ...       Men  \n",
       "554  5.0 out of 5 stars|| 3.0 out of 5 stars|| 5.0 ...       Men  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shoes_data[550:555]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>price</th>\n",
       "      <th>rating</th>\n",
       "      <th>total_reviews</th>\n",
       "      <th>product_description</th>\n",
       "      <th>reviews</th>\n",
       "      <th>reviews_rating</th>\n",
       "      <th>Shoe Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>585</th>\n",
       "      <td>Puma Men Emergence Running Shoes</td>\n",
       "      <td>‚Çπ2469.00</td>\n",
       "      <td>4.1 out of 5 stars</td>\n",
       "      <td>428 ratings</td>\n",
       "      <td>All new Emergence pushes the boundaries of our...</td>\n",
       "      <td>Happy|| Awesome 5 star üëåüòçüëç|| Awesome|| Looks g...</td>\n",
       "      <td>5.0 out of 5 stars|| 5.0 out of 5 stars|| 5.0 ...</td>\n",
       "      <td>Men</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>586</th>\n",
       "      <td>Hush Puppies Men Cash New Formal Shoes</td>\n",
       "      <td>‚Çπ2780.00</td>\n",
       "      <td>4.0 out of 5 stars</td>\n",
       "      <td>289 ratings</td>\n",
       "      <td>Experience great comfort walking in this pair ...</td>\n",
       "      <td>Defective / Rejected Product|| It seems Used P...</td>\n",
       "      <td>2.0 out of 5 stars|| 5.0 out of 5 stars|| 4.0 ...</td>\n",
       "      <td>Men</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>587</th>\n",
       "      <td>Power Men's Natural Engage Running Shoes</td>\n",
       "      <td>‚Çπ1220.00</td>\n",
       "      <td>4.3 out of 5 stars</td>\n",
       "      <td>411 ratings</td>\n",
       "      <td>Experience great comfort walking in this pair ...</td>\n",
       "      <td>Great shoes|| Great deal and amazing shoes.|| ...</td>\n",
       "      <td>5.0 out of 5 stars|| 5.0 out of 5 stars|| 5.0 ...</td>\n",
       "      <td>Men</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588</th>\n",
       "      <td>Hush Puppies Men's Chic Trim Crust Loafers</td>\n",
       "      <td>‚Çπ3149.00</td>\n",
       "      <td>4.0 out of 5 stars</td>\n",
       "      <td>198 ratings</td>\n",
       "      <td>Avail an exciting and edgy collection of sport...</td>\n",
       "      <td>Damaged products at discounted price!|| Leathe...</td>\n",
       "      <td>1.0 out of 5 stars|| 1.0 out of 5 stars|| 4.0 ...</td>\n",
       "      <td>Men</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>589</th>\n",
       "      <td>Adidas Men's Hyperon-1.0-m Running Shoe</td>\n",
       "      <td>‚Çπ1273.00</td>\n",
       "      <td>3.9 out of 5 stars</td>\n",
       "      <td>498 ratings</td>\n",
       "      <td>Adidas Men's HYPERON M LEGEAR/VISGRE/CBLACK/AC...</td>\n",
       "      <td>Great Product Verified as Original|| Misleadin...</td>\n",
       "      <td>5.0 out of 5 stars|| 4.0 out of 5 stars|| 2.0 ...</td>\n",
       "      <td>Men</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          title     price              rating  \\\n",
       "585            Puma Men Emergence Running Shoes  ‚Çπ2469.00  4.1 out of 5 stars   \n",
       "586      Hush Puppies Men Cash New Formal Shoes  ‚Çπ2780.00  4.0 out of 5 stars   \n",
       "587    Power Men's Natural Engage Running Shoes  ‚Çπ1220.00  4.3 out of 5 stars   \n",
       "588  Hush Puppies Men's Chic Trim Crust Loafers  ‚Çπ3149.00  4.0 out of 5 stars   \n",
       "589     Adidas Men's Hyperon-1.0-m Running Shoe  ‚Çπ1273.00  3.9 out of 5 stars   \n",
       "\n",
       "    total_reviews                                product_description  \\\n",
       "585   428 ratings  All new Emergence pushes the boundaries of our...   \n",
       "586   289 ratings  Experience great comfort walking in this pair ...   \n",
       "587   411 ratings  Experience great comfort walking in this pair ...   \n",
       "588   198 ratings  Avail an exciting and edgy collection of sport...   \n",
       "589   498 ratings  Adidas Men's HYPERON M LEGEAR/VISGRE/CBLACK/AC...   \n",
       "\n",
       "                                               reviews  \\\n",
       "585  Happy|| Awesome 5 star üëåüòçüëç|| Awesome|| Looks g...   \n",
       "586  Defective / Rejected Product|| It seems Used P...   \n",
       "587  Great shoes|| Great deal and amazing shoes.|| ...   \n",
       "588  Damaged products at discounted price!|| Leathe...   \n",
       "589  Great Product Verified as Original|| Misleadin...   \n",
       "\n",
       "                                        reviews_rating Shoe Type  \n",
       "585  5.0 out of 5 stars|| 5.0 out of 5 stars|| 5.0 ...       Men  \n",
       "586  2.0 out of 5 stars|| 5.0 out of 5 stars|| 4.0 ...       Men  \n",
       "587  5.0 out of 5 stars|| 5.0 out of 5 stars|| 5.0 ...       Men  \n",
       "588  1.0 out of 5 stars|| 1.0 out of 5 stars|| 4.0 ...       Men  \n",
       "589  5.0 out of 5 stars|| 4.0 out of 5 stars|| 2.0 ...       Men  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shoes_data[585:590]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>price</th>\n",
       "      <th>rating</th>\n",
       "      <th>total_reviews</th>\n",
       "      <th>product_description</th>\n",
       "      <th>reviews</th>\n",
       "      <th>reviews_rating</th>\n",
       "      <th>Shoe Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>540</th>\n",
       "      <td>ASICS Men's Jolt 3 Running Shoe</td>\n",
       "      <td>‚Çπ2618.00</td>\n",
       "      <td>4.1 out of 5 stars</td>\n",
       "      <td>260 ratings</td>\n",
       "      <td>Run and walk in comfort with the new JOLT‚Ñ¢ 3 s...</td>\n",
       "      <td>Heavy and an ungainly pair of shoes|| Very ver...</td>\n",
       "      <td>1.0 out of 5 stars|| 1.0 out of 5 stars|| 1.0 ...</td>\n",
       "      <td>Men</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>541</th>\n",
       "      <td>Nike Men's Todos Running Shoes</td>\n",
       "      <td>‚Çπ2186.00</td>\n",
       "      <td>4.0 out of 5 stars</td>\n",
       "      <td>1374 ratings</td>\n",
       "      <td>Sustainably crafted with families in mind the ...</td>\n",
       "      <td>Nike|| DUPLICATE PRODUCT|| Comfortable and ori...</td>\n",
       "      <td>5.0 out of 5 stars|| 1.0 out of 5 stars|| 5.0 ...</td>\n",
       "      <td>Men</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>542</th>\n",
       "      <td>US Polo Association Men's Lebron 2.0 Sneaker</td>\n",
       "      <td>‚Çπ2199.45</td>\n",
       "      <td>3.7 out of 5 stars</td>\n",
       "      <td>12 ratings</td>\n",
       "      <td>US Polo Association LEBRON 2.0 Men's Sneakers</td>\n",
       "      <td>Good luking</td>\n",
       "      <td>5.0 out of 5 stars</td>\n",
       "      <td>Men</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543</th>\n",
       "      <td>Red Chief Springer Derby Casual Shoe for Men R...</td>\n",
       "      <td>‚Çπ2546.00</td>\n",
       "      <td>3.8 out of 5 stars</td>\n",
       "      <td>112 ratings</td>\n",
       "      <td>Make your mark in the fashion world and gain t...</td>\n",
       "      <td>Very comfortable for Daily Use|| Perfect Fit||...</td>\n",
       "      <td>4.0 out of 5 stars|| 5.0 out of 5 stars|| 4.0 ...</td>\n",
       "      <td>Men</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544</th>\n",
       "      <td>Hush Puppies Men Fuel Slip On-2 Leather Formal...</td>\n",
       "      <td>‚Çπ2405.00</td>\n",
       "      <td>3.9 out of 5 stars</td>\n",
       "      <td>119 ratings</td>\n",
       "      <td>Experience great comfort walking in this pair ...</td>\n",
       "      <td>Hush puppies product|| Fake product|| Good one...</td>\n",
       "      <td>1.0 out of 5 stars|| 1.0 out of 5 stars|| 5.0 ...</td>\n",
       "      <td>Men</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title     price  \\\n",
       "540                    ASICS Men's Jolt 3 Running Shoe  ‚Çπ2618.00   \n",
       "541                     Nike Men's Todos Running Shoes  ‚Çπ2186.00   \n",
       "542       US Polo Association Men's Lebron 2.0 Sneaker  ‚Çπ2199.45   \n",
       "543  Red Chief Springer Derby Casual Shoe for Men R...  ‚Çπ2546.00   \n",
       "544  Hush Puppies Men Fuel Slip On-2 Leather Formal...  ‚Çπ2405.00   \n",
       "\n",
       "                 rating total_reviews  \\\n",
       "540  4.1 out of 5 stars   260 ratings   \n",
       "541  4.0 out of 5 stars  1374 ratings   \n",
       "542  3.7 out of 5 stars    12 ratings   \n",
       "543  3.8 out of 5 stars   112 ratings   \n",
       "544  3.9 out of 5 stars   119 ratings   \n",
       "\n",
       "                                   product_description  \\\n",
       "540  Run and walk in comfort with the new JOLT‚Ñ¢ 3 s...   \n",
       "541  Sustainably crafted with families in mind the ...   \n",
       "542      US Polo Association LEBRON 2.0 Men's Sneakers   \n",
       "543  Make your mark in the fashion world and gain t...   \n",
       "544  Experience great comfort walking in this pair ...   \n",
       "\n",
       "                                               reviews  \\\n",
       "540  Heavy and an ungainly pair of shoes|| Very ver...   \n",
       "541  Nike|| DUPLICATE PRODUCT|| Comfortable and ori...   \n",
       "542                                        Good luking   \n",
       "543  Very comfortable for Daily Use|| Perfect Fit||...   \n",
       "544  Hush puppies product|| Fake product|| Good one...   \n",
       "\n",
       "                                        reviews_rating Shoe Type  \n",
       "540  1.0 out of 5 stars|| 1.0 out of 5 stars|| 1.0 ...       Men  \n",
       "541  5.0 out of 5 stars|| 1.0 out of 5 stars|| 5.0 ...       Men  \n",
       "542                                 5.0 out of 5 stars       Men  \n",
       "543  4.0 out of 5 stars|| 5.0 out of 5 stars|| 4.0 ...       Men  \n",
       "544  1.0 out of 5 stars|| 1.0 out of 5 stars|| 5.0 ...       Men  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shoes_data[540:545]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>price</th>\n",
       "      <th>rating</th>\n",
       "      <th>total_reviews</th>\n",
       "      <th>product_description</th>\n",
       "      <th>reviews</th>\n",
       "      <th>reviews_rating</th>\n",
       "      <th>Shoe Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>Campus Men's Renegade Running Shoes</td>\n",
       "      <td>‚Çπ1682.00</td>\n",
       "      <td>3.7 out of 5 stars</td>\n",
       "      <td>90 ratings</td>\n",
       "      <td>Meet the ultimate street star. Campus Renegade...</td>\n",
       "      <td>VERY POOR QUALITY SHOES!|| Not sure of the gen...</td>\n",
       "      <td>1.0 out of 5 stars|| 2.0 out of 5 stars|| 5.0 ...</td>\n",
       "      <td>Men</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>Hush Puppies Men Boston New Slip On Leather Fo...</td>\n",
       "      <td>‚Çπ1750.00</td>\n",
       "      <td>4.1 out of 5 stars</td>\n",
       "      <td>189 ratings</td>\n",
       "      <td>Experience great comfort walking in this pair ...</td>\n",
       "      <td>Show Quality is pathetic it started to open up...</td>\n",
       "      <td>1.0 out of 5 stars|| 1.0 out of 5 stars|| 3.0 ...</td>\n",
       "      <td>Men</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>new balance Men's W520il5 Running Shoe</td>\n",
       "      <td>‚Çπ1574.00</td>\n",
       "      <td>3.5 out of 5 stars</td>\n",
       "      <td>7 ratings</td>\n",
       "      <td>A unique and versatile New Balance Running sho...</td>\n",
       "      <td>Nice shoes|| Very good product|| The product i...</td>\n",
       "      <td>5.0 out of 5 stars|| 5.0 out of 5 stars|| 2.0 ...</td>\n",
       "      <td>Men</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>Adidas Men's Lite Racer 2.0 Running Shoes</td>\n",
       "      <td>‚Çπ1883.00</td>\n",
       "      <td>4.0 out of 5 stars</td>\n",
       "      <td>1110 ratings</td>\n",
       "      <td>A dynamic go- everywhere shoe for the sports- ...</td>\n",
       "      <td>Authentic Adidas Shoes 11|| Nice oneüëç|| Authen...</td>\n",
       "      <td>4.0 out of 5 stars|| 5.0 out of 5 stars|| 5.0 ...</td>\n",
       "      <td>Men</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>Adidas Men's Strikerr M Running Shoes</td>\n",
       "      <td>‚Çπ1820.00</td>\n",
       "      <td>3.7 out of 5 stars</td>\n",
       "      <td>35 ratings</td>\n",
       "      <td>Profile: make running a part of your everyday ...</td>\n",
       "      <td>Color is like not carbon but more like a bleed...</td>\n",
       "      <td>3.0 out of 5 stars|| 1.0 out of 5 stars|| 5.0 ...</td>\n",
       "      <td>Men</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title     price  \\\n",
       "413                Campus Men's Renegade Running Shoes  ‚Çπ1682.00   \n",
       "414  Hush Puppies Men Boston New Slip On Leather Fo...  ‚Çπ1750.00   \n",
       "415             new balance Men's W520il5 Running Shoe  ‚Çπ1574.00   \n",
       "416          Adidas Men's Lite Racer 2.0 Running Shoes  ‚Çπ1883.00   \n",
       "417              Adidas Men's Strikerr M Running Shoes  ‚Çπ1820.00   \n",
       "\n",
       "                 rating total_reviews  \\\n",
       "413  3.7 out of 5 stars    90 ratings   \n",
       "414  4.1 out of 5 stars   189 ratings   \n",
       "415  3.5 out of 5 stars     7 ratings   \n",
       "416  4.0 out of 5 stars  1110 ratings   \n",
       "417  3.7 out of 5 stars    35 ratings   \n",
       "\n",
       "                                   product_description  \\\n",
       "413  Meet the ultimate street star. Campus Renegade...   \n",
       "414  Experience great comfort walking in this pair ...   \n",
       "415  A unique and versatile New Balance Running sho...   \n",
       "416  A dynamic go- everywhere shoe for the sports- ...   \n",
       "417  Profile: make running a part of your everyday ...   \n",
       "\n",
       "                                               reviews  \\\n",
       "413  VERY POOR QUALITY SHOES!|| Not sure of the gen...   \n",
       "414  Show Quality is pathetic it started to open up...   \n",
       "415  Nice shoes|| Very good product|| The product i...   \n",
       "416  Authentic Adidas Shoes 11|| Nice oneüëç|| Authen...   \n",
       "417  Color is like not carbon but more like a bleed...   \n",
       "\n",
       "                                        reviews_rating Shoe Type  \n",
       "413  1.0 out of 5 stars|| 2.0 out of 5 stars|| 5.0 ...       Men  \n",
       "414  1.0 out of 5 stars|| 1.0 out of 5 stars|| 3.0 ...       Men  \n",
       "415  5.0 out of 5 stars|| 5.0 out of 5 stars|| 2.0 ...       Men  \n",
       "416  4.0 out of 5 stars|| 5.0 out of 5 stars|| 5.0 ...       Men  \n",
       "417  3.0 out of 5 stars|| 1.0 out of 5 stars|| 5.0 ...       Men  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shoes_data[413:418]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>price</th>\n",
       "      <th>rating</th>\n",
       "      <th>total_reviews</th>\n",
       "      <th>product_description</th>\n",
       "      <th>reviews</th>\n",
       "      <th>reviews_rating</th>\n",
       "      <th>Shoe Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>Reebok Men's Ridge Runner Running Shoe</td>\n",
       "      <td>‚Çπ1413.00</td>\n",
       "      <td>3.9 out of 5 stars</td>\n",
       "      <td>30 ratings</td>\n",
       "      <td>The footwear allows your foot to flex as it wa...</td>\n",
       "      <td>Worth it!!!|| Very vood shoes|| It's copy not ...</td>\n",
       "      <td>5.0 out of 5 stars|| 5.0 out of 5 stars|| 1.0 ...</td>\n",
       "      <td>Men</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>Bacca Bucci Zeus Men Fashion Sneakers/Running ...</td>\n",
       "      <td>‚Çπ1299.00</td>\n",
       "      <td>4.5 out of 5 stars</td>\n",
       "      <td>11 ratings</td>\n",
       "      <td>Bacca Bucci Zeus Men Fashion Sneakers/Running ...</td>\n",
       "      <td>This shoes are parfect size comfortable and pr...</td>\n",
       "      <td>5.0 out of 5 stars|| 5.0 out of 5 stars|| 5.0 ...</td>\n",
       "      <td>Men</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>Red Tape Men's Walking Shoes</td>\n",
       "      <td>‚Çπ1049.00</td>\n",
       "      <td>3.9 out of 5 stars</td>\n",
       "      <td>7 ratings</td>\n",
       "      <td>Red Tape flow+ slip-on with ‚Äòmemory foam‚Äô inso...</td>\n",
       "      <td>Good|| Poor quality</td>\n",
       "      <td>5.0 out of 5 stars|| 1.0 out of 5 stars</td>\n",
       "      <td>Men</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>Adidas Men's Hyperon-1.0-m Running Shoe</td>\n",
       "      <td>‚Çπ1509.00</td>\n",
       "      <td>3.9 out of 5 stars</td>\n",
       "      <td>508 ratings</td>\n",
       "      <td>Adidas Men's HYPERON M LEGEAR/VISGRE/CBLACK/AC...</td>\n",
       "      <td>Great Product Verified as Original|| Misleadin...</td>\n",
       "      <td>5.0 out of 5 stars|| 4.0 out of 5 stars|| 2.0 ...</td>\n",
       "      <td>Men</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>Puma Men's Flex Hype Idp Sneaker</td>\n",
       "      <td>‚Çπ1719.00</td>\n",
       "      <td>3.9 out of 5 stars</td>\n",
       "      <td>20 ratings</td>\n",
       "      <td>Crafted with fine technology and futuristic de...</td>\n",
       "      <td>After 1 day use|| Why no one can pick the retu...</td>\n",
       "      <td>5.0 out of 5 stars|| 1.0 out of 5 stars|| 5.0 ...</td>\n",
       "      <td>Men</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title     price  \\\n",
       "325             Reebok Men's Ridge Runner Running Shoe  ‚Çπ1413.00   \n",
       "326  Bacca Bucci Zeus Men Fashion Sneakers/Running ...  ‚Çπ1299.00   \n",
       "327                       Red Tape Men's Walking Shoes  ‚Çπ1049.00   \n",
       "328            Adidas Men's Hyperon-1.0-m Running Shoe  ‚Çπ1509.00   \n",
       "329                   Puma Men's Flex Hype Idp Sneaker  ‚Çπ1719.00   \n",
       "\n",
       "                 rating total_reviews  \\\n",
       "325  3.9 out of 5 stars    30 ratings   \n",
       "326  4.5 out of 5 stars    11 ratings   \n",
       "327  3.9 out of 5 stars     7 ratings   \n",
       "328  3.9 out of 5 stars   508 ratings   \n",
       "329  3.9 out of 5 stars    20 ratings   \n",
       "\n",
       "                                   product_description  \\\n",
       "325  The footwear allows your foot to flex as it wa...   \n",
       "326  Bacca Bucci Zeus Men Fashion Sneakers/Running ...   \n",
       "327  Red Tape flow+ slip-on with ‚Äòmemory foam‚Äô inso...   \n",
       "328  Adidas Men's HYPERON M LEGEAR/VISGRE/CBLACK/AC...   \n",
       "329  Crafted with fine technology and futuristic de...   \n",
       "\n",
       "                                               reviews  \\\n",
       "325  Worth it!!!|| Very vood shoes|| It's copy not ...   \n",
       "326  This shoes are parfect size comfortable and pr...   \n",
       "327                                Good|| Poor quality   \n",
       "328  Great Product Verified as Original|| Misleadin...   \n",
       "329  After 1 day use|| Why no one can pick the retu...   \n",
       "\n",
       "                                        reviews_rating Shoe Type  \n",
       "325  5.0 out of 5 stars|| 5.0 out of 5 stars|| 1.0 ...       Men  \n",
       "326  5.0 out of 5 stars|| 5.0 out of 5 stars|| 5.0 ...       Men  \n",
       "327            5.0 out of 5 stars|| 1.0 out of 5 stars       Men  \n",
       "328  5.0 out of 5 stars|| 4.0 out of 5 stars|| 2.0 ...       Men  \n",
       "329  5.0 out of 5 stars|| 1.0 out of 5 stars|| 5.0 ...       Men  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shoes_data[325:330]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ú–æ–¥–µ–ª—å —á–∞—Å—Ç–æ —Å–∏–ª—å–Ω–æ –æ—à–∏–±–∞–µ—Ç—Å—è, –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞—è, —á—Ç–æ –∫—Ä–æ—Å—Å–æ–≤–∫–∏ –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ –¥–æ—Ä–æ–∂–µ, —á–µ–º –Ω–∞ —Å–∞–º–æ–º –¥–µ–ª–µ. –¢–∞–∫–æ–µ —á–∞—Å—Ç–æ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç —Å –∫—Ä–æ—Å—Å–æ–≤–∫–∞–º–∏ –∞–¥–∏–¥–∞—Å, –Ω–æ –¥–ª—è –¥—Ä—É–≥–∏—Ö —Ñ–∏—Ä–º —Ç–æ–∂–µ —Ç–∞–∫–æ–µ —Å–ª—É—á–∞–µ—Ç—Å—è. –£ –º–µ–Ω—è –µ—Å—Ç—å –¥–≤–∞ –ø—Ä–µ–¥–ø–æ–ª–æ–∂–µ–Ω–∏—è:\n",
    "\n",
    "* –£ –∞–¥–∏–¥–∞—Å–∞ –µ—Å—Ç—å —Ä—è–¥ –æ–±—É–≤–∏, –∫–æ—Ç–æ—Ä–∞—è —Å—Ç–æ–∏—Ç –¥–µ—à–µ–≤–ª–µ, —á–µ–º –¥—Ä—É–≥–∏–µ –∫—Ä–æ—Å—Å–æ–≤–∫–∏ –±—Ä–µ–Ω–¥–∞, –∏ –¥–æ—Ä–æ–≥–∏—Ö –∫—Ä–æ—Å—Å–æ–≤–æ–∫ –±–æ–ª—å—à–µ. –¢–æ–≥–¥–∞ –ª–æ–≥–∏—á–Ω–æ, —á—Ç–æ –º–æ–¥–µ–ª—å –æ—à–∏–±–∞–µ—Ç—Å—è\n",
    "* –í–æ–∑–º–æ–∂–Ω–æ –≤ –¥–∞—Ç–∞—Å–µ—Ç–µ –µ—Å—Ç—å —Ç–æ–≤–∞—Ä—ã —Å–æ —Å–∫–∏–¥–∫–æ–π (–Ω–æ —ç—Ç–æ–≥–æ —è –Ω–µ –∑–Ω–∞—é). –ï—Å–ª–∏ —Ç–∞–∫–∏–µ –≤–¥—Ä—É–≥ –µ—Å—Ç—å, —Ç–æ —Ö–æ—Ä–æ—à–æ –±—ã–ª–æ –±—ã —É–∫–∞–∑—ã–≤–∞—Ç—å —Ä–∞–∑–º–µ—Ä —Å–∫–∏–¥–∫–∏, —á—Ç–æ–±—ã –º–æ–∂–Ω–æ –±—ã–ª–æ –≤—ã—á–∏—Å–ª–∏—Ç—å –ø–æ–ª–Ω—É—é —Å—Ç–æ–∏–º–æ—Å—Ç—å —ç—Ç–∏—Ö —Ç–æ–≤–∞—Ä–æ–≤. –ï—â–µ –º–æ–∂–Ω–æ –±—ã–ª–æ –±—ã –¥–æ–±–∞–≤–∏—Ç—å –±–∏–Ω–∞—Ä–Ω—ã–π –ø—Ä–∏–∑–Ω–∞–∫ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ç–æ–≥–æ, –µ—Å—Ç—å –Ω–∞ —Ç–æ–≤–∞—Ä —Å–∫–∏–¥–∫–∞ –∏–ª–∏ –Ω–µ—Ç, —Ç–∞–∫ –∫–∞–∫ —á–∞—Å—Ç–æ —Å–∫–∏–¥–∫–∏ –¥–µ–π—Å—Ç–≤—É—é—Ç –Ω–∞ —Ç–æ–≤–∞—Ä—ã –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ–≥–æ –±—Ä–µ–Ω–¥–∞"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –í—ã–≤–æ–¥—ã"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–î—É–º–∞—é, —á—Ç–æ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è —Ä–∞–±–æ—Ç—ã –æ–±–µ–∏—Ö –ª—É—á—à–∏—Ö –º–æ–¥–µ–ª–µ–π –º–æ–∂–Ω–æ –±—ã–ª–æ –±—ã —Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞—Ç—å –≤—ã–±–æ—Ä–∫—É, —á—Ç–æ–±—ã –≤—Å–µ —Ü–µ–Ω–æ–≤—ã–µ –∫–ª–∞—Å—Å—ã –±—ã–ª–∏ —Ö–æ—Ä–æ—à–æ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω—ã –≤ –¥–∞–Ω–Ω—ã—Ö (—Ç–æ –µ—Å—Ç—å –¥–æ–±–∞–≤–∏—Ç—å –≤ –¥–∞–Ω–Ω—ã–µ –ø–æ–±–æ–ª—å—à–µ –¥–æ—Ä–æ–≥–∏—Ö —Ç–æ–≤–∞—Ä–æ–≤). –ï—â–µ –≤ –∏–¥–µ–∞–ª–µ —è –±—ã –ø–æ–¥–∫–ª—é—á–∏–ª–∞ –Ω–µ—Ä–æ–≤—Å–∫—É—é –º–æ–¥–µ–ª—å, —á—Ç–æ–±—ã –∏–∑–≤–ª–µ–∫–∞—Ç—å –∏–∑ –Ω–∞–∑–≤–∞–Ω–∏—è —Ç–æ–≤–∞—Ä–æ–≤ –±—Ä–µ–Ω–¥—ã, —Ç–∞–∫ –∫–∞–∫ –±—Ä–µ–Ω–¥—ã –º–æ–∂–Ω–æ —Ä–∞–∑–¥–µ–ª–∏—Ç—å –Ω–∞ –±–æ–ª–µ–µ –¥–æ—Ä–æ–≥–∏–µ/–¥–µ—à–µ–≤—ã–µ. –ú–æ–∂–Ω–æ –±—ã–ª–æ –±—ã –≤—ã–Ω–µ—Å—Ç–∏ –±—Ä–µ–Ω–¥—ã –≤ –∫–∞—á–µ—Å—Ç–≤–µ –æ—Ç–¥–µ–ª—å–Ω–æ–≥–æ –ø—Ä–∏–∑–Ω–∞–∫–∞ –∏, —Ç–∞–∫–∏–º –æ–±—Ä–∞–∑–æ–º, –¥–∞—Ç—å —ç—Ç–æ–º—É –ø—Ä–∏–∑–Ω–∞–∫—É –±–û–ª—å—à–∏–π –≤–µ—Å."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –ó–∞–¥–∞–Ω–∏–µ 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –ú—ã —É–∂–µ –ø–æ—Å–º–æ—Ç—Ä–µ–ª–∏ –Ω–∞ –æ–±—â—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –¥–∞–Ω–Ω—ã—Ö, –ø–æ—ç—Ç–æ–º—É —Ç–µ–ø–µ—Ä—å –ø–æ—Å–º–æ—Ç—Ä–∏–º –Ω–∞ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ –¥–ª—è –ø–µ—Ä–≤–æ–π –∑–∞–¥–∞—á–∏ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –æ—Ç–∑—ã–≤–æ–≤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.distplot(shoes_data_new['total_reviews_new'], bins=17, color='pink')\n",
    "plt.title('Distribution of reviews')\n",
    "plt.ylabel('%')\n",
    "plt.xlabel('amount of reviews');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ö–∞–∫ –º—ã –≤–∏–¥–∏–º, –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–æ —Ç–æ–≤–∞—Ä–æ–≤ –∏–º–µ—é—Ç –ø—Ä–∏–º–µ—Ä–Ω–æ –¥–æ 2500 –æ—Ç–∑—ã–≤–æ–≤. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –æ—Ü–µ–Ω–æ–∫ —Ç–æ–≤–∞—Ä–æ–≤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fc2ed7e14f0>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAU0AAAEvCAYAAADBzJOVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAARoUlEQVR4nO3da7BdZX3H8e+PQLkoDjAJmBI0tJNqg6OCMaVDaxVsQVHATmnjVJs6tPRCZ3TsjAbG8fIiM/FFvbV1FC/TeKWxKqSgbQOKTmcqGBCBEChpiZCGIRFHQWWg4L8v9ordHE7O2c/hrHN2cr6fmTN7rWc/az//Z3bym7XX2mvtVBWSpNEcMt8FSNKBxNCUpAaGpiQ1MDQlqYGhKUkNDE1JanDofBfwdCxevLiWL18+32VIOsjcdNNN36+qJZM9d0CH5vLly9m6det8lyHpIJPke/t7zo/nktTA0JSkBoamJDUwNCWpgaEpSQ0MTUlqYGhKUgNDU5IaGJqS1MDQlKQGhqYkNTigrz2XFqrl667pfYydG87tfYwDkXuaktTA0JSkBoamJDUwNCWpgaEpSQ0MTUlqYGhKUgNDU5IaGJqS1MDQlKQGhqYkNTA0JamBoSlJDQxNSWpgaEpSA0NTkhoYmpLUwNCUpAaGpiQ1MDQlqYGhKUkNDE1JamBoSlIDQ1OSGhiaktTA0JSkBoamJDUwNCWpgaEpSQ0MTUlqYGhKUgNDU5Ia9B6aSRYl+U6Sq7v145JsSXJ393jsUN9Lk+xIcleSs/uuTZJazcWe5puB7UPr64DrqmoFcF23TpKVwBrgFOAc4MNJFs1BfZI0sl5DM8ky4Fzg40PN5wMbu+WNwAVD7VdU1aNVdQ+wA1jdZ32S1KrvPc0PAG8DfjbUdkJV3Q/QPR7ftZ8I3DfUb1fXJkljo7fQTPIaYE9V3TTqJpO01SSve3GSrUm27t2792nVKEmt+tzTPAM4L8lO4ArgzCSfAR5IshSge9zT9d8FnDS0/TJg98QXrarLq2pVVa1asmRJj+VL0lP1FppVdWlVLauq5QxO8Hytqt4AbAbWdt3WAld1y5uBNUkOT3IysAK4sa/6JGkmDp2HMTcAm5JcBNwLXAhQVduSbALuAB4HLqmqJ+ahPknarzkJzaq6Hri+W34QOGs//dYD6+eiJkmaCa8IkqQGhqYkNTA0JamBoSlJDQxNSWpgaEpSA0NTkhoYmpLUwNCUpAaGpiQ1MDQlqYGhKUkNDE1JamBoSlIDQ1OSGhiaktTA0JSkBoamJDUwNCWpgaEpSQ0MTUlqYGhKUgNDU5IaGJqS1MDQlKQGhqYkNTA0JamBoSlJDQxNSWpgaEpSA0NTkhoYmpLUwNCUpAaGpiQ1MDQlqcGh812ApPG0fN01vY+xc8O5vY8x29zTlKQGhqYkNTA0JamBoSlJDQxNSWpgaEpSA0NTkhoYmpLUwNCUpAaGpiQ1MDQlqUFvoZnkiCQ3Jvlukm1J3tO1H5dkS5K7u8djh7a5NMmOJHclObuv2iRppvrc03wUOLOqXgS8GDgnyenAOuC6qloBXNetk2QlsAY4BTgH+HCSRT3WJ0nNegvNGvhxt3pY91fA+cDGrn0jcEG3fD5wRVU9WlX3ADuA1X3VJ0kz0esxzSSLktwC7AG2VNUNwAlVdT9A93h81/1E4L6hzXd1bZI0NnoNzap6oqpeDCwDVid5wRTdM9lLPKVTcnGSrUm27t27d7ZKlaSRzMnZ86r6IXA9g2OVDyRZCtA97um67QJOGtpsGbB7kte6vKpWVdWqJUuW9Fq3JE3U59nzJUmO6ZaPBF4J3AlsBtZ23dYCV3XLm4E1SQ5PcjKwArixr/okaSb6/LmLpcDG7gz4IcCmqro6yX8Am5JcBNwLXAhQVduSbALuAB4HLqmqJ3qsT5Ka9RaaVXUrcOok7Q8CZ+1nm/XA+r5qkqSnyyuCJKnBSKE5zVlvSVowRt3T/Eh3SeRf7ju5I0kL0UihWVW/Afwhg68EbU3yuSS/3WtlkjSGRj6mWVV3A+8A3g78FvChJHcm+d2+ipOkcTPqMc0XJnk/sB04E3htVf1qt/z+HuuTpLEy6leO/g74GHBZVT2yr7Gqdid5Ry+VSdIYGjU0Xw08su/L5kkOAY6oqp9W1ad7q06SxsyoxzSvBY4cWj+qa5OkBWXU0Dxi6N6YdMtH9VOSJI2vUUPzJ0lO27eS5CXAI1P0l6SD0qjHNN8CfCHJvlu1LQX+oJ+SJGl8jRSaVfXtJM8HnsfgZsF3VtX/9lqZJI2hlrscvRRY3m1zahKq6lO9VCVJY2qk0EzyaeCXgVuAffe4LMDQlLSgjLqnuQpYWVVP+c0eSVpIRj17fjvw7D4LkaQDwah7mouBO5LcCDy6r7GqzuulKkkaU6OG5rv7LEKSDhSjfuXoG0meC6yoqmuTHAUs6rc0SRo/o94a7k+BfwI+2jWdCFzZV1GSNK5G/Xh+CbAauAEGNyROcnxvVUkHqOXrrpnvEtSzUc+eP1pVj+1bSXIog+9pStKCMmpofiPJZcCR3W8DfQH45/7KkqTxNGporgP2ArcBfwZ8hcHvBUnSgjLq2fOfMfi5i4/1W44kjbdRrz2/h0mOYVbVL816RZI0xlquPd/nCOBC4LjZL0eSxttIxzSr6sGhv/+pqg8w+PleSVpQRv14ftrQ6iEM9jyP7qUiSRpjo348/5uh5ceBncDvz3o1kjTmRj17/oq+C5GkA8GoH8/fOtXzVfW+2SlHksZby9nzlwKbu/XXAt8E7uujKEkaVy03IT6tqh4GSPJu4AtV9Sd9FSZJ42jUyyifAzw2tP4Yg1+mlKQFZdQ9zU8DNyb5MoMrg16Hv0QpaQEa9ez5+iRfBX6za3pTVX2nv7IkaTyN+vEc4Cjgoar6ILAryck91SRJY2vUn7t4F/B24NKu6TDgM30VJUnjatQ9zdcB5wE/Aaiq3XgZpaQFaNTQfKyqiu72cEme0V9JkjS+Rg3NTUk+ChzT/TLltXhDYkkL0LRnz5ME+Efg+cBDwPOAd1bVlp5rk6SxM21oVlUlubKqXgIYlJIWtFE/nn8ryUt7rUSSDgCjhuYrGATnfyW5NcltSW6daoMkJyX5epLtSbYleXPXflySLUnu7h6PHdrm0iQ7ktyV5OyZT0uS+jHlx/Mkz6mqe4FXzeC1Hwf+uqpuTnI0cFOSLcAfA9dV1YYk6xj8PPDbk6wE1gCnAL8IXJvkV6rqiRmMLUm9mG5P80qAqvoe8L6q+t7w31QbVtX9VXVzt/wwsB04ETgf2Nh12whc0C2fD1xRVY9W1T3ADmD1TCYlSX2ZLjQztDzjn+tNshw4FbgBOKGq7odBsALHd91O5Mn359zVtUnS2JguNGs/yyNL8kzgi8BbquqhqbpOM/6+17s4ydYkW/fu3TuTkiRpxqYLzRcleSjJw8ALu+WHkjycZKoABCDJYQwC87NV9aWu+YEkS7vnlwJ7uvZdwElDmy8Ddk98zaq6vKpWVdWqJUuWTFeCJM2qKUOzqhZV1bOq6uiqOrRb3rf+rKm27b4U/wlg+4TfENoMrO2W1wJXDbWvSXJ4dwelFcCNM5mUJPVl1JsQz8QZwBuB25Lc0rVdBmxgcFnmRcC9wIUAVbUtySbgDgZn3i/xzLmkcdNbaFbVvzP5cUqAs/azzXpgfV81SdLT1XITYkla8AxNSWpgaEpSA0NTkhoYmpLUwNCUpAaGpiQ1MDQlqYGhKUkNDE1JamBoSlIDQ1OSGhiaktTA0JSkBoamJDUwNCWpgaEpSQ0MTUlqYGhKUgNDU5IaGJqS1MDQlKQGhqYkNTA0JamBoSlJDQxNSWpgaEpSA0NTkhoYmpLUwNCUpAaGpiQ1MDQlqYGhKUkNDE1JamBoSlIDQ1OSGhiaktTA0JSkBoamJDUwNCWpgaEpSQ0MTUlqYGhKUgNDU5IaGJqS1MDQlKQGhqYkNegtNJN8MsmeJLcPtR2XZEuSu7vHY4eeuzTJjiR3JTm7r7ok6enoc0/zH4BzJrStA66rqhXAdd06SVYCa4BTum0+nGRRj7VJ0oz0FppV9U3gBxOazwc2dssbgQuG2q+oqker6h5gB7C6r9okaabm+pjmCVV1P0D3eHzXfiJw31C/XV3bUyS5OMnWJFv37t3ba7GSNNG4nAjKJG01WcequryqVlXVqiVLlvRcliQ92VyH5gNJlgJ0j3u69l3ASUP9lgG757g2SZrWXIfmZmBtt7wWuGqofU2Sw5OcDKwAbpzj2iRpWof29cJJPg+8HFicZBfwLmADsCnJRcC9wIUAVbUtySbgDuBx4JKqeqKv2iRppnoLzap6/X6eOms//dcD6/uqR1q+7pr5LkEHgXE5ESRJBwRDU5IaGJqS1MDQlKQGhqYkNTA0JamBoSlJDQxNSWpgaEpSA0NTkhoYmpLUwNCUpAaGpiQ1MDQlqYGhKUkNerufpiRNZ67ucbpzw7mz9lruaUpSA0NTkhoYmpLUwNCUpAaGpiQ1MDQlqYGhKUkNDE1JamBoSlIDQ1OSGhiaktTA0JSkBoamJDUwNCWpgaEpSQ0MTUlqYGhKUgNDU5IaGJqS1MDQlKQGhqYkNTA0JamBoSlJDQxNSWpgaEpSA0NTkhoYmpLU4ND5LkBavu6a+S5BGpl7mpLUwD1NTcm9QOnJxi40k5wDfBBYBHy8qjbM5uvPRQjs3HBu72NImh9j9fE8ySLg74FXASuB1ydZOb9VSdL/G6vQBFYDO6rqv6vqMeAK4Px5rkmSfm7cPp6fCNw3tL4L+LV5qmXsebxRmnvjFpqZpK2e1CG5GLi4W/1xkrsax1gMfH8GtY0s753f8cd0bMf3vZ+38fPe5vGfu78nxi00dwEnDa0vA3YPd6iqy4HLZzpAkq1VtWqm2z9d8zn+Qp77Qh9/Ic99tscft2Oa3wZWJDk5yS8Aa4DN81yTJP3cWO1pVtXjSf4K+FcGXzn6ZFVtm+eyJOnnxio0AarqK8BXehxixh/tD4LxF/LcF/r4C3nuszp+qmr6XpIkYPyOaUrSWDsoQzPJJ5PsSXL7fp5Pkg8l2ZHk1iSnzfH4L0/yoyS3dH/vnMWxT0ry9STbk2xL8uZJ+vQ2/xHH73P+RyS5Mcl3u/HfM0mfXuY/4ti9zX1ojEVJvpPk6kme6/vf/lRj9zr3JDuT3Na99tZJnp+duVfVQfcHvAw4Dbh9P8+/Gvgqg++Fng7cMMfjvxy4uqe5LwVO65aPBv4TWDlX8x9x/D7nH+CZ3fJhwA3A6XMx/xHH7m3uQ2O8FfjcZOPMwb/9qcbude7ATmDxFM/PytwPyj3Nqvom8IMpupwPfKoGvgUck2TpHI7fm6q6v6pu7pYfBrYzuNJqWG/zH3H83nRz+nG3elj3N/HAfS/zH3HsXiVZBpwLfHw/XXp770cYe77NytwPytAcwWSXa87Zf+zOr3cf476a5JQ+BkiyHDiVwR7PsDmZ/xTjQ4/z7z4i3gLsAbZU1ZzNf4Sxod/3/gPA24Cf7ef5Pt/76caGfudewL8luSmDKwcnmpW5L9TQnPZyzZ7dDDy3ql4E/C1w5WwPkOSZwBeBt1TVQxOfnmSTWZ3/NOP3Ov+qeqKqXszgirLVSV4wsbzJNpujsXube5LXAHuq6qapuk3S9rTnPuLYff+7P6OqTmNwl7RLkrxsYpmTbNM894UamtNertmnqnpo38e4Gnwv9bAki2fr9ZMcxiCwPltVX5qkS6/zn278vuc/NM4PgeuBcyY81fv7v7+xe577GcB5SXYyuEPYmUk+M6FPX3Ofduy+3/eq2t097gG+zOCuacNmZe4LNTQ3A3/UnU07HfhRVd0/V4MneXaSdMurGbwPD87Sawf4BLC9qt63n269zX+U8Xue/5Ikx3TLRwKvBO6c0K2X+Y8ydp9zr6pLq2pZVS1ncAny16rqDRO69TL3Ucbu+X1/RpKj9y0DvwNM/PbKrMx97K4Img1JPs/gTN3iJLuAdzE4KE9VfYTBFUevBnYAPwXeNMfj/x7wF0keBx4B1lR3em8WnAG8EbitO7YGcBnwnKHx+5z/KOP3Of+lwMYMbmh9CLCpqq5O8udD4/c1/1HG7nPuk5qjuY8ydp9zPwH4cpfJhwKfq6p/6WPuXhEkSQ0W6sdzSZoRQ1OSGhiaktTA0JSkBoamJDUwNCWpgaEpSQ0MTUlq8H9WNK9JT0pgqgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "shoes_data_new['rating_new'].plot(kind='hist', figsize=(5, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–°—Ä–µ–¥–Ω—è—è –¥–ª–∏–Ω–∞ –æ—Ç–∑—ã–≤–æ–≤ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Å—Ä–µ–¥–Ω–µ–π –æ—Ü–µ–Ω–∫–∏ —Ç–æ–≤–∞—Ä–∞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def likes():\n",
    "    list_mentioned = list(shoes_data_new.rating_new.unique())\n",
    "    dict_amount = {}\n",
    "    dict_likes = {}\n",
    "    for x in list_mentioned:\n",
    "        counter = 0\n",
    "        if x != 'nan':\n",
    "            likes_per_person = shoes_data_new[shoes_data_new.rating_new == x].mean_len_reviews\n",
    "            l = list(likes_per_person)\n",
    "            dict_amount[x] = len(list(l))\n",
    "            for i in l:\n",
    "                counter += i\n",
    "            dict_likes[x] = counter\n",
    "    return dict_amount, dict_likes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def medium(dict_amount, dict_likes):\n",
    "    med_likes = {}\n",
    "    for key in dict_likes:\n",
    "        try:\n",
    "            s = dict_likes[key]/dict_amount[key]\n",
    "            med_likes[key] = round(s)\n",
    "        except:\n",
    "            continue\n",
    "    a = sorted(med_likes.items(), key=lambda x: x[1], reverse=True)[:15]\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph(a):\n",
    "    nums = [w[-1] for w in a]\n",
    "    labs = [w[0] for w in a]\n",
    "    plt.figure(figsize=(20, 10), dpi=200)\n",
    "    plt.bar(range(len(labs)), nums)\n",
    "\n",
    "    plt.title('–°—Ä–µ–¥–Ω—è—è –¥–ª–∏–Ω–∞ –æ—Ç–∑—ã–≤–æ–≤, –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Å—Ä–µ–¥–Ω–∏—Ö —Ä–µ–π—Ç–∏–Ω–≥–æ–≤')\n",
    "    plt.ylabel('–°—Ä–µ–¥–Ω—è—è —Ü–µ–Ω–∞ —Ç–æ–≤–∞—Ä–æ–≤')\n",
    "    plt.xlabel('–°—Ä–µ–¥–Ω–∏–π —Ä–µ–π—Ç–∏–Ω–≥ —Ç–æ–≤–∞—Ä–æ–≤')\n",
    "    plt.xticks(range(len(labs)), labs, rotation=90)\n",
    "    #plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = likes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = medium(dl[0], dl[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 4000x2000 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "graph(h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ö–æ—Ä—Ä–µ–ª—è—Ü–∏–∏ –º–µ–∂–¥—É —Å—Ä–µ–¥–Ω–µ–π –¥–ª–∏–Ω–æ–π –æ—Ç–∑—ã–≤–æ–≤ –∏ –æ—Ü–µ–Ω–∫–∞–º–∏ —Ç–æ–≤–∞—Ä–æ–≤ –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏ –Ω–µ—Ç. –†–∞–∑–≤–µ —á—Ç–æ –æ—Ç–∑—ã–≤—ã –¥–ª—è —Ç–æ–≤–∞—Ä–æ–≤ —Å–æ —Å—Ä–µ–¥–Ω–∏–º —Ä–µ–π—Ç–∏–Ω–≥–æ–º 2.2 –∏–º–µ—é—Ç –±–û–ª—å—à—É—é –¥–ª–∏–Ω—É. –ú–æ–∂–Ω–æ –±—ã–ª–æ –±—ã –ø—Ä–µ–¥–ø–æ–ª–æ–∂–∏—Ç—å, —á—Ç–æ –ª—é–¥–∏ –æ—Å—Ç–∞–≤–ª—è—é—Ç –±–æ–ª–µ–µ –¥–ª–∏–Ω–Ω—ã–µ –æ—Ç–∑—ã–≤—ã, –∫–æ–≥–¥–∞ –∏–º –Ω–µ –Ω—Ä–∞–≤–∏—Ç—Å—è —Ç–æ–≤–∞—Ä, –Ω–æ —Ç–æ–≥–¥–∞ –∏ –æ—Ç–∑—ã–≤—ã –Ω–∞ —Ç–æ–≤–∞—Ä—ã —Å–æ —Å—Ä–µ–¥–Ω–µ–π –æ—Ü–µ–Ω–∫–æ–π 1.0 –±—ã–ª–∏ –±—ã –¥–ª–∏–Ω–Ω–µ–µ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –ü–æ–ø—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ –º–æ–¥–µ–ª–∏"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ù–æ –¥–ª—è –Ω–∞—á–∞–ª–∞ –æ–∫—Ä—É–≥–ª–∏–º —Å—Ä–µ–¥–Ω–∏–µ –æ—Ç–∑—ã–≤—ã —Ç–æ–≤–∞—Ä–æ–≤. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def int_r(num):\n",
    "    num = int(num + (0.5 if num > 0 else -0.5))\n",
    "    return num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1230it [00:02, 429.39it/s]\n"
     ]
    }
   ],
   "source": [
    "round_ratings = []\n",
    "for index, row in tqdm(shoes_data_new.iterrows()):\n",
    "    round_rating = int_r(row['rating_new'])\n",
    "    round_ratings.append(round_rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "shoes_data_new['rounded_rating'] = round_ratings\n",
    "shoes_data_new_2['rounded_rating'] = round_ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ú–µ—Ç–æ–¥ –±–ª–∏–∂–∞–π—à–µ–≥–æ —Å–æ—Å–µ–¥–∞ —Å BoW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–í –∫–∞—á–µ—Å—Ç–≤–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –≤–æ–∑—å–º–µ–º:\n",
    "\n",
    "* –≤–µ–∫—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω–Ω—ã–µ –Ω–∞–∑–≤–∞–Ω–∏—è —Ç–æ–≤–∞—Ä–æ–≤\n",
    "* —Ü–µ–Ω—ã —Ç–æ–≤–∞—Ä–æ–≤\n",
    "* –≤–µ–∫—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω–Ω—ã–µ –æ–ø–∏—Å–∞–Ω–∏—è —Ç–æ–≤–∞—Ä–æ–≤\n",
    "* –≤–µ–∫—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω–Ω—ã–µ –æ—Ç–∑—ã–≤—ã —Ç–æ–≤–∞—Ä–æ–≤\n",
    "* –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ—Ç–∑—ã–≤–æ–≤ –Ω–∞ —Ç–æ–≤–∞—Ä—ã\n",
    "* —Ç–∏–ø –æ–±—É–≤–∏ (–º/–∂)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc=0.8128\n",
      "micro F1=0.8128, micro P=0.8128, micro R=0.8128\n",
      "macro F1=0.4840, macro P=0.5079, macro R=0.4858\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "all_columns = list(shoes_data_new.columns)\n",
    "feature_columns = [col for col in all_columns if ('title_' in col) or ('product_description_' in col)\n",
    "                  or ('reviews_' in col)]\n",
    "feature_columns.append('price_new')\n",
    "feature_columns.append('shoe_type')\n",
    "X_train, X_test, y_train, y_test = train_test_split(shoes_data_new[feature_columns], shoes_data_new.rounded_rating,\n",
    "                                                    test_size=0.33, random_state=42)\n",
    "clf = KNeighborsClassifier().fit(X_train, y_train)\n",
    "predicted = clf.predict(X_test)\n",
    "acc = accuracy_score(predicted, y_test)\n",
    "micro_f1 = f1_score(predicted, y_test, average = 'micro')\n",
    "micro_p = precision_score(predicted, y_test, average = 'micro')\n",
    "micro_r = recall_score(predicted, y_test, average = 'micro')\n",
    "macro_f1 = f1_score(predicted, y_test, average = 'macro')\n",
    "macro_p = precision_score(predicted, y_test, average = 'macro')\n",
    "macro_r = recall_score(predicted, y_test, average = 'macro')\n",
    "print('acc={0:1.4f}'.format(acc))\n",
    "print('micro F1={0:1.4f}, micro P={1:1.4f}, micro R={2:1.4f}'.format(micro_f1, micro_p, micro_r))\n",
    "print('macro F1={0:1.4f}, macro P={1:1.4f}, macro R={2:1.4f}\\n'.format(macro_f1, macro_p, macro_r))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–¢–µ–ø–µ—Ä—å –ø–æ–ø—Ä–æ–±—É–µ–º –ø–æ—Å–º–æ—Ç—Ä–µ—Ç—å –Ω–∞ –∫–∞—á–µ—Å—Ç–≤–æ –ø—Ä–∏ —Å–ª–µ–¥—É—é—â–µ–º –Ω–∞–±–æ—Ä–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤:\n",
    "\n",
    "* —Ü–µ–Ω—ã —Ç–æ–≤–∞—Ä–æ–≤\n",
    "* –≤–µ–∫—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω–Ω—ã–µ –æ–ø–∏—Å–∞–Ω–∏—è —Ç–æ–≤–∞—Ä–æ–≤\n",
    "* –≤–µ–∫—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω–Ω—ã–µ –æ—Ç–∑—ã–≤—ã —Ç–æ–≤–∞—Ä–æ–≤\n",
    "* –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ—Ç–∑—ã–≤–æ–≤ –Ω–∞ —Ç–æ–≤–∞—Ä—ã\n",
    "* —Ç–∏–ø –æ–±—É–≤–∏ (–º/–∂)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc=0.8128\n",
      "micro F1=0.8128, micro P=0.8128, micro R=0.8128\n",
      "macro F1=0.4840, macro P=0.5079, macro R=0.4858\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "all_columns = list(shoes_data_new.columns)\n",
    "feature_columns = [col for col in all_columns if ('product_description_' in col)\n",
    "                  or ('reviews_' in col)]\n",
    "feature_columns.append('price_new')\n",
    "feature_columns.append('shoe_type')\n",
    "X_train, X_test, y_train, y_test = train_test_split(shoes_data_new[feature_columns], shoes_data_new.rounded_rating,\n",
    "                                                    test_size=0.33, random_state=42)\n",
    "clf = KNeighborsClassifier().fit(X_train, y_train)\n",
    "predicted = clf.predict(X_test)\n",
    "acc = accuracy_score(predicted, y_test)\n",
    "micro_f1 = f1_score(predicted, y_test, average = 'micro')\n",
    "micro_p = precision_score(predicted, y_test, average = 'micro')\n",
    "micro_r = recall_score(predicted, y_test, average = 'micro')\n",
    "macro_f1 = f1_score(predicted, y_test, average = 'macro')\n",
    "macro_p = precision_score(predicted, y_test, average = 'macro')\n",
    "macro_r = recall_score(predicted, y_test, average = 'macro')\n",
    "print('acc={0:1.4f}'.format(acc))\n",
    "print('micro F1={0:1.4f}, micro P={1:1.4f}, micro R={2:1.4f}'.format(micro_f1, micro_p, micro_r))\n",
    "print('macro F1={0:1.4f}, macro P={1:1.4f}, macro R={2:1.4f}\\n'.format(macro_f1, macro_p, macro_r))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–¢–µ–ø–µ—Ä—å –ø–æ–ø—Ä–æ–±—É–µ–º –ø–æ—Å–º–æ—Ç—Ä–µ—Ç—å –Ω–∞ –∫–∞—á–µ—Å—Ç–≤–æ –ø—Ä–∏ —Å–ª–µ–¥—É—é—â–µ–º –Ω–∞–±–æ—Ä–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤:\n",
    "\n",
    "* –≤–µ–∫—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω–Ω—ã–µ –æ–ø–∏—Å–∞–Ω–∏—è —Ç–æ–≤–∞—Ä–æ–≤\n",
    "* –≤–µ–∫—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω–Ω—ã–µ –æ—Ç–∑—ã–≤—ã —Ç–æ–≤–∞—Ä–æ–≤\n",
    "* –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ—Ç–∑—ã–≤–æ–≤ –Ω–∞ —Ç–æ–≤–∞—Ä—ã\n",
    "* —Ç–∏–ø –æ–±—É–≤–∏ (–º/–∂)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc=0.8227\n",
      "micro F1=0.8227, micro P=0.8227, micro R=0.8227\n",
      "macro F1=0.6050, macro P=0.6006, macro R=0.6979\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_columns = list(shoes_data_new.columns)\n",
    "feature_columns = [col for col in all_columns if ('product_description_' in col)\n",
    "                  or ('reviews_' in col)]\n",
    "feature_columns.append('shoe_type')\n",
    "X_train, X_test, y_train, y_test = train_test_split(shoes_data_new[feature_columns], shoes_data_new.rounded_rating,\n",
    "                                                    test_size=0.33, random_state=42)\n",
    "clf = KNeighborsClassifier().fit(X_train, y_train)\n",
    "predicted = clf.predict(X_test)\n",
    "acc = accuracy_score(predicted, y_test)\n",
    "micro_f1 = f1_score(predicted, y_test, average = 'micro')\n",
    "micro_p = precision_score(predicted, y_test, average = 'micro')\n",
    "micro_r = recall_score(predicted, y_test, average = 'micro')\n",
    "macro_f1 = f1_score(predicted, y_test, average = 'macro')\n",
    "macro_p = precision_score(predicted, y_test, average = 'macro')\n",
    "macro_r = recall_score(predicted, y_test, average = 'macro')\n",
    "print('acc={0:1.4f}'.format(acc))\n",
    "print('micro F1={0:1.4f}, micro P={1:1.4f}, micro R={2:1.4f}'.format(micro_f1, micro_p, micro_r))\n",
    "print('macro F1={0:1.4f}, macro P={1:1.4f}, macro R={2:1.4f}\\n'.format(macro_f1, macro_p, macro_r))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ë–µ–∑ —É–∫–∞–∑–∞–Ω–∏—è —Ü–µ–Ω—ã –∫–∞—á–µ—Å—Ç–≤–æ —É–ª—É—á—à–∏–ª–æ—Å—å"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–¢–µ–ø–µ—Ä—å –ø–æ–ø—Ä–æ–±—É–µ–º –ø–æ—Å–º–æ—Ç—Ä–µ—Ç—å –Ω–∞ –∫–∞—á–µ—Å—Ç–≤–æ –ø—Ä–∏ —Å–ª–µ–¥—É—é—â–µ–º –Ω–∞–±–æ—Ä–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤:\n",
    "\n",
    "* –≤–µ–∫—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω–Ω—ã–µ –æ—Ç–∑—ã–≤—ã —Ç–æ–≤–∞—Ä–æ–≤\n",
    "* –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ—Ç–∑—ã–≤–æ–≤ –Ω–∞ —Ç–æ–≤–∞—Ä—ã\n",
    "* —Ç–∏–ø –æ–±—É–≤–∏ (–º/–∂)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc=0.7833\n",
      "micro F1=0.7833, micro P=0.7833, micro R=0.7833\n",
      "macro F1=0.4228, macro P=0.4569, macro R=0.4265\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "all_columns = list(shoes_data_new.columns)\n",
    "feature_columns = [col for col in all_columns if 'reviews_' in col]\n",
    "feature_columns.append('shoe_type')\n",
    "X_train, X_test, y_train, y_test = train_test_split(shoes_data_new[feature_columns], shoes_data_new.rounded_rating,\n",
    "                                                    test_size=0.33, random_state=42)\n",
    "clf = KNeighborsClassifier().fit(X_train, y_train)\n",
    "predicted = clf.predict(X_test)\n",
    "acc = accuracy_score(predicted, y_test)\n",
    "micro_f1 = f1_score(predicted, y_test, average = 'micro')\n",
    "micro_p = precision_score(predicted, y_test, average = 'micro')\n",
    "micro_r = recall_score(predicted, y_test, average = 'micro')\n",
    "macro_f1 = f1_score(predicted, y_test, average = 'macro')\n",
    "macro_p = precision_score(predicted, y_test, average = 'macro')\n",
    "macro_r = recall_score(predicted, y_test, average = 'macro')\n",
    "print('acc={0:1.4f}'.format(acc))\n",
    "print('micro F1={0:1.4f}, micro P={1:1.4f}, micro R={2:1.4f}'.format(micro_f1, micro_p, micro_r))\n",
    "print('macro F1={0:1.4f}, macro P={1:1.4f}, macro R={2:1.4f}\\n'.format(macro_f1, macro_p, macro_r))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ë–µ–∑ –≤–µ–∫—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω–Ω—ã—Ö –æ–ø–∏—Å–∞–Ω–∏–π —Ç–æ–≤–∞—Ä–æ–≤ –∫–∞—á–µ—Å—Ç–≤–æ —É—Ö—É–¥—à–∏–ª–æ—Å—å"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–¢–µ–ø–µ—Ä—å –ø–æ–ø—Ä–æ–±—É–µ–º –ø–æ—Å–º–æ—Ç—Ä–µ—Ç—å –Ω–∞ –∫–∞—á–µ—Å—Ç–≤–æ –ø—Ä–∏ —Å–ª–µ–¥—É—é—â–µ–º –Ω–∞–±–æ—Ä–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤:\n",
    "\n",
    "* –≤–µ–∫—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω–Ω—ã–µ –æ–ø–∏—Å–∞–Ω–∏—è —Ç–æ–≤–∞—Ä–æ–≤\n",
    "* –≤–µ–∫—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω–Ω—ã–µ –æ—Ç–∑—ã–≤—ã —Ç–æ–≤–∞—Ä–æ–≤\n",
    "* –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ—Ç–∑—ã–≤–æ–≤ –Ω–∞ —Ç–æ–≤–∞—Ä—ã"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc=0.8227\n",
      "micro F1=0.8227, micro P=0.8227, micro R=0.8227\n",
      "macro F1=0.6050, macro P=0.6006, macro R=0.6979\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_columns = list(shoes_data_new.columns)\n",
    "feature_columns = [col for col in all_columns if ('product_description_' in col)\n",
    "                  or ('reviews_' in col)]\n",
    "\n",
    "feature_columns.append('shoe_type')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(shoes_data_new[feature_columns], shoes_data_new.rounded_rating,\n",
    "                                                    test_size=0.33, random_state=42)\n",
    "clf = KNeighborsClassifier().fit(X_train, y_train)\n",
    "predicted = clf.predict(X_test)\n",
    "acc = accuracy_score(predicted, y_test)\n",
    "micro_f1 = f1_score(predicted, y_test, average = 'micro')\n",
    "micro_p = precision_score(predicted, y_test, average = 'micro')\n",
    "micro_r = recall_score(predicted, y_test, average = 'micro')\n",
    "macro_f1 = f1_score(predicted, y_test, average = 'macro')\n",
    "macro_p = precision_score(predicted, y_test, average = 'macro')\n",
    "macro_r = recall_score(predicted, y_test, average = 'macro')\n",
    "print('acc={0:1.4f}'.format(acc))\n",
    "print('micro F1={0:1.4f}, micro P={1:1.4f}, micro R={2:1.4f}'.format(micro_f1, micro_p, micro_r))\n",
    "print('macro F1={0:1.4f}, macro P={1:1.4f}, macro R={2:1.4f}\\n'.format(macro_f1, macro_p, macro_r))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–í –¥–∞–ª—å–Ω–µ–π—à–µ–º –±—É–¥–µ–º —Ä–∞–±–æ—Ç–∞—Ç—å —Å –ø–æ—Å–ª–µ–¥–Ω–∏–º –Ω–∞–±–æ—Ä–æ–º –ø—Ä–∏–∑–Ω–∞–∫–æ–≤. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ú–µ—Ç–æ–¥ –±–ª–∏–∂–∞–π—à–µ–≥–æ —Å–æ—Å–µ–¥–∞ —Å TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc=0.7931\n",
      "micro F1=0.7931, micro P=0.7931, micro R=0.7931\n",
      "macro F1=0.5535, macro P=0.5923, macro R=0.5418\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_columns = list(shoes_data_new.columns)\n",
    "feature_columns = [col for col in all_columns if ('product_description_' in col)\n",
    "                  or ('reviews_' in col)]\n",
    "\n",
    "feature_columns.append('shoe_type')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(shoes_data_new_2[feature_columns], shoes_data_new_2.rounded_rating,\n",
    "                                                    test_size=0.33, random_state=42)\n",
    "clf = KNeighborsClassifier().fit(X_train, y_train)\n",
    "predicted = clf.predict(X_test)\n",
    "acc = accuracy_score(predicted, y_test)\n",
    "micro_f1 = f1_score(predicted, y_test, average = 'micro')\n",
    "micro_p = precision_score(predicted, y_test, average = 'micro')\n",
    "micro_r = recall_score(predicted, y_test, average = 'micro')\n",
    "macro_f1 = f1_score(predicted, y_test, average = 'macro')\n",
    "macro_p = precision_score(predicted, y_test, average = 'macro')\n",
    "macro_r = recall_score(predicted, y_test, average = 'macro')\n",
    "print('acc={0:1.4f}'.format(acc))\n",
    "print('micro F1={0:1.4f}, micro P={1:1.4f}, micro R={2:1.4f}'.format(micro_f1, micro_p, micro_r))\n",
    "print('macro F1={0:1.4f}, macro P={1:1.4f}, macro R={2:1.4f}\\n'.format(macro_f1, macro_p, macro_r))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–º—É–ª—å—Ç–∏–Ω–æ–º–∏–∞–ª—å–Ω—ã–π –Ω–∞–∏–≤–Ω—ã–π –ë–∞–π–µ—Å–æ–≤—Å–∫–∏–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä c BoW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc=0.5493\n",
      "micro F1=0.5493, micro P=0.5493, micro R=0.5493\n",
      "macro F1=0.4589, macro P=0.4959, macro R=0.5418\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "all_columns = list(shoes_data_new.columns)\n",
    "feature_columns = [col for col in all_columns if ('product_description_' in col)\n",
    "                  or ('reviews_' in col)]\n",
    "\n",
    "feature_columns.append('shoe_type')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(shoes_data_new[feature_columns], shoes_data_new.rounded_rating,\n",
    "                                                    test_size=0.33, random_state=42)\n",
    "clf = MultinomialNB().fit(X_train, y_train)\n",
    "predicted = clf.predict(X_test)\n",
    "acc = accuracy_score(predicted, y_test)\n",
    "micro_f1 = f1_score(predicted, y_test, average = 'micro')\n",
    "micro_p = precision_score(predicted, y_test, average = 'micro')\n",
    "micro_r = recall_score(predicted, y_test, average = 'micro')\n",
    "macro_f1 = f1_score(predicted, y_test, average = 'macro')\n",
    "macro_p = precision_score(predicted, y_test, average = 'macro')\n",
    "macro_r = recall_score(predicted, y_test, average = 'macro')\n",
    "print('acc={0:1.4f}'.format(acc))\n",
    "print('micro F1={0:1.4f}, micro P={1:1.4f}, micro R={2:1.4f}'.format(micro_f1, micro_p, micro_r))\n",
    "print('macro F1={0:1.4f}, macro P={1:1.4f}, macro R={2:1.4f}\\n'.format(macro_f1, macro_p, macro_r))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–º—É–ª—å—Ç–∏–Ω–æ–º–∏–∞–ª—å–Ω—ã–π –Ω–∞–∏–≤–Ω—ã–π –ë–∞–π–µ—Å–æ–≤—Å–∫–∏–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä c TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc=0.6576\n",
      "micro F1=0.6576, micro P=0.6576, micro R=0.6576\n",
      "macro F1=0.3162, macro P=0.3614, macro R=0.3306\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "all_columns = list(shoes_data_new.columns)\n",
    "feature_columns = [col for col in all_columns if ('product_description_' in col)\n",
    "                  or ('reviews_' in col)]\n",
    "\n",
    "feature_columns.append('shoe_type')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(shoes_data_new_2[feature_columns], shoes_data_new_2.rounded_rating,\n",
    "                                                    test_size=0.33, random_state=42)\n",
    "clf = MultinomialNB().fit(X_train, y_train)\n",
    "predicted = clf.predict(X_test)\n",
    "acc = accuracy_score(predicted, y_test)\n",
    "micro_f1 = f1_score(predicted, y_test, average = 'micro')\n",
    "micro_p = precision_score(predicted, y_test, average = 'micro')\n",
    "micro_r = recall_score(predicted, y_test, average = 'micro')\n",
    "macro_f1 = f1_score(predicted, y_test, average = 'macro')\n",
    "macro_p = precision_score(predicted, y_test, average = 'macro')\n",
    "macro_r = recall_score(predicted, y_test, average = 'macro')\n",
    "print('acc={0:1.4f}'.format(acc))\n",
    "print('micro F1={0:1.4f}, micro P={1:1.4f}, micro R={2:1.4f}'.format(micro_f1, micro_p, micro_r))\n",
    "print('macro F1={0:1.4f}, macro P={1:1.4f}, macro R={2:1.4f}\\n'.format(macro_f1, macro_p, macro_r))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–õ–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫–∞—è —Ä–µ–≥—Ä–µ—Å—Å–∏—è —Å BoW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc=0.8399\n",
      "micro F1=0.8399, micro P=0.8399, micro R=0.8399\n",
      "macro F1=0.6771, macro P=0.6420, macro R=0.7568\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_columns = list(shoes_data_new.columns)\n",
    "feature_columns = [col for col in all_columns if ('product_description_' in col)\n",
    "                  or ('reviews_' in col)]\n",
    "\n",
    "feature_columns.append('shoe_type')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(shoes_data_new[feature_columns], shoes_data_new.rounded_rating,\n",
    "                                                    test_size=0.33, random_state=42)\n",
    "clf = LogisticRegression().fit(X_train, y_train)\n",
    "predicted = clf.predict(X_test)\n",
    "acc = accuracy_score(predicted, y_test)\n",
    "micro_f1 = f1_score(predicted, y_test, average = 'micro')\n",
    "micro_p = precision_score(predicted, y_test, average = 'micro')\n",
    "micro_r = recall_score(predicted, y_test, average = 'micro')\n",
    "macro_f1 = f1_score(predicted, y_test, average = 'macro')\n",
    "macro_p = precision_score(predicted, y_test, average = 'macro')\n",
    "macro_r = recall_score(predicted, y_test, average = 'macro')\n",
    "print('acc={0:1.4f}'.format(acc))\n",
    "print('micro F1={0:1.4f}, micro P={1:1.4f}, micro R={2:1.4f}'.format(micro_f1, micro_p, micro_r))\n",
    "print('macro F1={0:1.4f}, macro P={1:1.4f}, macro R={2:1.4f}\\n'.format(macro_f1, macro_p, macro_r))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–õ–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫–∞—è —Ä–µ–≥—Ä–µ—Å—Å–∏—è —Å TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc=0.8300\n",
      "micro F1=0.8300, micro P=0.8300, micro R=0.8300\n",
      "macro F1=0.3466, macro P=0.3303, macro R=0.4604\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "all_columns = list(shoes_data_new.columns)\n",
    "feature_columns = [col for col in all_columns if ('product_description_' in col)\n",
    "                  or ('reviews_' in col)]\n",
    "\n",
    "feature_columns.append('shoe_type')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(shoes_data_new_2[feature_columns], shoes_data_new_2.rounded_rating,\n",
    "                                                    test_size=0.33, random_state=42)\n",
    "clf = LogisticRegression().fit(X_train, y_train)\n",
    "predicted = clf.predict(X_test)\n",
    "acc = accuracy_score(predicted, y_test)\n",
    "micro_f1 = f1_score(predicted, y_test, average = 'micro')\n",
    "micro_p = precision_score(predicted, y_test, average = 'micro')\n",
    "micro_r = recall_score(predicted, y_test, average = 'micro')\n",
    "macro_f1 = f1_score(predicted, y_test, average = 'macro')\n",
    "macro_p = precision_score(predicted, y_test, average = 'macro')\n",
    "macro_r = recall_score(predicted, y_test, average = 'macro')\n",
    "print('acc={0:1.4f}'.format(acc))\n",
    "print('micro F1={0:1.4f}, micro P={1:1.4f}, micro R={2:1.4f}'.format(micro_f1, micro_p, micro_r))\n",
    "print('macro F1={0:1.4f}, macro P={1:1.4f}, macro R={2:1.4f}\\n'.format(macro_f1, macro_p, macro_r))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ú–µ—Ç–æ–¥ –æ–ø–æ—Ä–Ω—ã—Ö –≤–µ–∫—Ç–æ—Ä–æ–≤ —Å BoW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc=0.8276\n",
      "micro F1=0.8276, micro P=0.8276, micro R=0.8276\n",
      "macro F1=0.5169, macro P=0.4981, macro R=0.5764\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "all_columns = list(shoes_data_new.columns)\n",
    "feature_columns = [col for col in all_columns if ('product_description_' in col)\n",
    "                  or ('reviews_' in col)]\n",
    "\n",
    "feature_columns.append('shoe_type')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(shoes_data_new[feature_columns], shoes_data_new.rounded_rating,\n",
    "                                                    test_size=0.33, random_state=42)\n",
    "clf = LinearSVC().fit(X_train, y_train)\n",
    "predicted = clf.predict(X_test)\n",
    "acc = accuracy_score(predicted, y_test)\n",
    "micro_f1 = f1_score(predicted, y_test, average = 'micro')\n",
    "micro_p = precision_score(predicted, y_test, average = 'micro')\n",
    "micro_r = recall_score(predicted, y_test, average = 'micro')\n",
    "macro_f1 = f1_score(predicted, y_test, average = 'macro')\n",
    "macro_p = precision_score(predicted, y_test, average = 'macro')\n",
    "macro_r = recall_score(predicted, y_test, average = 'macro')\n",
    "print('acc={0:1.4f}'.format(acc))\n",
    "print('micro F1={0:1.4f}, micro P={1:1.4f}, micro R={2:1.4f}'.format(micro_f1, micro_p, micro_r))\n",
    "print('macro F1={0:1.4f}, macro P={1:1.4f}, macro R={2:1.4f}\\n'.format(macro_f1, macro_p, macro_r))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ú–µ—Ç–æ–¥ –æ–ø–æ—Ä–Ω—ã—Ö –≤–µ–∫—Ç–æ—Ä–æ–≤ —Å TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc=0.3005\n",
      "micro F1=0.3005, micro P=0.3005, micro R=0.3005\n",
      "macro F1=0.3609, macro P=0.3366, macro R=0.5147\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "all_columns = list(shoes_data_new.columns)\n",
    "feature_columns = [col for col in all_columns if ('product_description_' in col)\n",
    "                  or ('reviews_' in col)]\n",
    "\n",
    "feature_columns.append('shoe_type')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(shoes_data_new_2[feature_columns], shoes_data_new_2.rounded_rating,\n",
    "                                                    test_size=0.33, random_state=42)\n",
    "clf = LinearSVC().fit(X_train, y_train)\n",
    "predicted = clf.predict(X_test)\n",
    "acc = accuracy_score(predicted, y_test)\n",
    "micro_f1 = f1_score(predicted, y_test, average = 'micro')\n",
    "micro_p = precision_score(predicted, y_test, average = 'micro')\n",
    "micro_r = recall_score(predicted, y_test, average = 'micro')\n",
    "macro_f1 = f1_score(predicted, y_test, average = 'macro')\n",
    "macro_p = precision_score(predicted, y_test, average = 'macro')\n",
    "macro_r = recall_score(predicted, y_test, average = 'macro')\n",
    "print('acc={0:1.4f}'.format(acc))\n",
    "print('micro F1={0:1.4f}, micro P={1:1.4f}, micro R={2:1.4f}'.format(micro_f1, micro_p, micro_r))\n",
    "print('macro F1={0:1.4f}, macro P={1:1.4f}, macro R={2:1.4f}\\n'.format(macro_f1, macro_p, macro_r))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–î–µ—Ä–µ–≤—å—è —Ä–µ—à–µ–Ω–∏–π —Å BoW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc=0.8276\n",
      "micro F1=0.8276, micro P=0.8276, micro R=0.8276\n",
      "macro F1=0.6641, macro P=0.7132, macro R=0.6329\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_columns = list(shoes_data_new.columns)\n",
    "feature_columns = [col for col in all_columns if ('product_description_' in col)\n",
    "                  or ('reviews_' in col)]\n",
    "\n",
    "feature_columns.append('shoe_type')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(shoes_data_new[feature_columns], shoes_data_new.rounded_rating,\n",
    "                                                    test_size=0.33, random_state=42)\n",
    "clf = DecisionTreeClassifier().fit(X_train, y_train)\n",
    "predicted = clf.predict(X_test)\n",
    "acc = accuracy_score(predicted, y_test)\n",
    "micro_f1 = f1_score(predicted, y_test, average = 'micro')\n",
    "micro_p = precision_score(predicted, y_test, average = 'micro')\n",
    "micro_r = recall_score(predicted, y_test, average = 'micro')\n",
    "macro_f1 = f1_score(predicted, y_test, average = 'macro')\n",
    "macro_p = precision_score(predicted, y_test, average = 'macro')\n",
    "macro_r = recall_score(predicted, y_test, average = 'macro')\n",
    "print('acc={0:1.4f}'.format(acc))\n",
    "print('micro F1={0:1.4f}, micro P={1:1.4f}, micro R={2:1.4f}'.format(micro_f1, micro_p, micro_r))\n",
    "print('macro F1={0:1.4f}, macro P={1:1.4f}, macro R={2:1.4f}\\n'.format(macro_f1, macro_p, macro_r))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–î–µ—Ä–µ–≤—å—è —Ä–µ—à–µ–Ω–∏–π —Å TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc=0.8522\n",
      "micro F1=0.8522, micro P=0.8522, micro R=0.8522\n",
      "macro F1=0.5949, macro P=0.5911, macro R=0.6040\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "all_columns = list(shoes_data_new.columns)\n",
    "feature_columns = [col for col in all_columns if ('product_description_' in col)\n",
    "                  or ('reviews_' in col)]\n",
    "\n",
    "feature_columns.append('shoe_type')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(shoes_data_new_2[feature_columns], shoes_data_new_2.rounded_rating,\n",
    "                                                    test_size=0.33, random_state=42)\n",
    "clf = DecisionTreeClassifier().fit(X_train, y_train)\n",
    "predicted = clf.predict(X_test)\n",
    "acc = accuracy_score(predicted, y_test)\n",
    "micro_f1 = f1_score(predicted, y_test, average = 'micro')\n",
    "micro_p = precision_score(predicted, y_test, average = 'micro')\n",
    "micro_r = recall_score(predicted, y_test, average = 'micro')\n",
    "macro_f1 = f1_score(predicted, y_test, average = 'macro')\n",
    "macro_p = precision_score(predicted, y_test, average = 'macro')\n",
    "macro_r = recall_score(predicted, y_test, average = 'macro')\n",
    "print('acc={0:1.4f}'.format(acc))\n",
    "print('micro F1={0:1.4f}, micro P={1:1.4f}, micro R={2:1.4f}'.format(micro_f1, micro_p, micro_r))\n",
    "print('macro F1={0:1.4f}, macro P={1:1.4f}, macro R={2:1.4f}\\n'.format(macro_f1, macro_p, macro_r))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lasso c BoW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean absolute error =  0.3027417317439193\n"
     ]
    }
   ],
   "source": [
    "all_columns = list(shoes_data_new.columns)\n",
    "feature_columns = [col for col in all_columns if ('product_description_' in col)\n",
    "                  or ('reviews_' in col)]\n",
    "\n",
    "feature_columns.append('shoe_type')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(shoes_data_new[feature_columns], shoes_data_new.rating_new,\n",
    "                                                    test_size=0.33, random_state=42)\n",
    "clf = Lasso(alpha=10).fit(X_train, y_train)\n",
    "predicted = clf.predict(X_test)\n",
    "m = mean_absolute_error(y_test, predicted)\n",
    "print('mean absolute error = ', m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lasso c TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean absolute error =  0.3027417317439193\n"
     ]
    }
   ],
   "source": [
    "all_columns = list(shoes_data_new.columns)\n",
    "feature_columns = [col for col in all_columns if ('product_description_' in col)\n",
    "                  or ('reviews_' in col)]\n",
    "\n",
    "feature_columns.append('shoe_type')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(shoes_data_new_2[feature_columns], shoes_data_new_2.rating_new,\n",
    "                                                    test_size=0.33, random_state=42)\n",
    "clf = Lasso(alpha=10).fit(X_train, y_train)\n",
    "predicted = clf.predict(X_test)\n",
    "m = mean_absolute_error(y_test, predicted)\n",
    "print('mean absolute error = ', m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ridge c Bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean absolute error =  0.27807912881017616\n"
     ]
    }
   ],
   "source": [
    "all_columns = list(shoes_data_new.columns)\n",
    "feature_columns = [col for col in all_columns if ('product_description_' in col)\n",
    "                  or ('reviews_' in col)]\n",
    "\n",
    "feature_columns.append('shoe_type')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(shoes_data_new[feature_columns], shoes_data_new.rating_new,\n",
    "                                                    test_size=0.33, random_state=42)\n",
    "clf = Ridge().fit(X_train, y_train)\n",
    "predicted = clf.predict(X_test)\n",
    "m = mean_absolute_error(y_test, predicted)\n",
    "print('mean absolute error = ', m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ridge c TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean absolute error =  0.22115618801406348\n"
     ]
    }
   ],
   "source": [
    "all_columns = list(shoes_data_new.columns)\n",
    "feature_columns = [col for col in all_columns if ('product_description_' in col)\n",
    "                  or ('reviews_' in col)]\n",
    "\n",
    "feature_columns.append('shoe_type')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(shoes_data_new_2[feature_columns], shoes_data_new_2.rating_new,\n",
    "                                                    test_size=0.33, random_state=42)\n",
    "clf = Ridge().fit(X_train, y_train)\n",
    "predicted = clf.predict(X_test)\n",
    "m = mean_absolute_error(y_test, predicted)\n",
    "print('mean absolute error = ', m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LinearSVR c BoW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean absolute error =  0.5300621391961294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    }
   ],
   "source": [
    "all_columns = list(shoes_data_new.columns)\n",
    "feature_columns = [col for col in all_columns if ('product_description_' in col)\n",
    "                  or ('reviews_' in col)]\n",
    "\n",
    "feature_columns.append('shoe_type')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(shoes_data_new[feature_columns], shoes_data_new.rating_new,\n",
    "                                                    test_size=0.33, random_state=42)\n",
    "clf = LinearSVR(C=1).fit(X_train, y_train)\n",
    "predicted = clf.predict(X_test)\n",
    "m = mean_absolute_error(y_test, predicted)\n",
    "print('mean absolute error = ', m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LinearSVR c TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean absolute error =  0.2948453956840351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    }
   ],
   "source": [
    "all_columns = list(shoes_data_new.columns)\n",
    "feature_columns = [col for col in all_columns if ('product_description_' in col)\n",
    "                  or ('reviews_' in col)]\n",
    "\n",
    "feature_columns.append('shoe_type')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(shoes_data_new_2[feature_columns], shoes_data_new_2.rating_new,\n",
    "                                                    test_size=0.33, random_state=42)\n",
    "clf = LinearSVR(C=1).fit(X_train, y_train)\n",
    "predicted = clf.predict(X_test)\n",
    "m = mean_absolute_error(y_test, predicted)\n",
    "print('mean absolute error = ', m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –õ—É—á—à–∏–µ –º–æ–¥–µ–ª–∏  –∫–ª–∞—Å—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏: \n",
    "\n",
    "1) –õ–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫–∞—è —Ä–µ–≥—Ä–µ—Å—Å–∏—è —Å BoW\n",
    "\n",
    "2) –î–µ—Ä–µ–≤—å—è —Ä–µ—à–µ–Ω–∏–π —Å TFIDF\n",
    "\n",
    "–ü–æ–ø—Ä–æ–±—É–µ–º –ø—Ä–∏–º–µ–Ω–∏—Ç—å –≥—Ä–∏–¥—Å–µ—Ä—á –∫ –∫–∞–∂–¥–æ–π –∏–∑ –Ω–∏—Ö"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –ì—Ä–∏–¥—Å–µ—Ä—á –¥–ª—è –ª–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫–æ–π —Ä–µ–≥—Ä–µ—Å—Å–∏–∏ —Å BoW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_split.py:670: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1407, in fit\n",
      "    fold_coefs_ = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1029, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 847, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 765, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 759, in _logistic_regression_path\n",
      "    args=(X, target, 1. / C, sample_weight),\n",
      "ZeroDivisionError: float division by zero\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1407, in fit\n",
      "    fold_coefs_ = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1029, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 847, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 765, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 759, in _logistic_regression_path\n",
      "    args=(X, target, 1. / C, sample_weight),\n",
      "ZeroDivisionError: float division by zero\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1407, in fit\n",
      "    fold_coefs_ = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1029, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 847, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 765, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 759, in _logistic_regression_path\n",
      "    args=(X, target, 1. / C, sample_weight),\n",
      "ZeroDivisionError: float division by zero\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1407, in fit\n",
      "    fold_coefs_ = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1029, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 847, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 765, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 759, in _logistic_regression_path\n",
      "    args=(X, target, 1. / C, sample_weight),\n",
      "ZeroDivisionError: float division by zero\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1407, in fit\n",
      "    fold_coefs_ = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1029, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 847, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 765, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 759, in _logistic_regression_path\n",
      "    args=(X, target, 1. / C, sample_weight),\n",
      "ZeroDivisionError: float division by zero\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=LogisticRegression(),\n",
       "             param_grid={'C': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
       "                         'penalty': ['l1', 'l2', 'elasticnet', 'none']},\n",
       "             scoring=make_scorer(accuracy_score))"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_columns = list(shoes_data_new.columns)\n",
    "feature_columns = [col for col in all_columns if ('product_description_' in col)\n",
    "                  or ('reviews_' in col)]\n",
    "\n",
    "feature_columns.append('shoe_type')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(shoes_data_new[feature_columns], shoes_data_new.rounded_rating,\n",
    "                                                    test_size=0.33, random_state=42)\n",
    "\n",
    "parameters = {'penalty':['l1', 'l2', 'elasticnet', 'none'], 'C':[i for i in range(11)]}\n",
    "svc =  LogisticRegression()\n",
    "scorer = make_scorer(accuracy_score)\n",
    "clf = GridSearchCV(estimator=svc, param_grid=parameters, scoring=scorer)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–õ—É—á—à–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤: \n",
      "{'C': 1, 'penalty': 'l2'}\n",
      "–ó–Ω–∞—á–µ–Ω–∏—è –º–µ—Ç—Ä–∏–∫ –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ: \n",
      "acc=0.8399\n",
      "micro F1=0.8399, micro P=0.8399, micro R=0.8399\n",
      "macro F1=0.6771, macro P=0.6420, macro R=0.7568\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('–õ—É—á—à–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤: ')\n",
    "print(clf.best_params_)\n",
    "predicted = clf.predict(X_test)\n",
    "print('–ó–Ω–∞—á–µ–Ω–∏—è –º–µ—Ç—Ä–∏–∫ –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ: ')\n",
    "predicted = clf.predict(X_test)\n",
    "acc = accuracy_score(predicted, y_test)\n",
    "micro_f1 = f1_score(predicted, y_test, average = 'micro')\n",
    "micro_p = precision_score(predicted, y_test, average = 'micro')\n",
    "micro_r = recall_score(predicted, y_test, average = 'micro')\n",
    "macro_f1 = f1_score(predicted, y_test, average = 'macro')\n",
    "macro_p = precision_score(predicted, y_test, average = 'macro')\n",
    "macro_r = recall_score(predicted, y_test, average = 'macro')\n",
    "print('acc={0:1.4f}'.format(acc))\n",
    "print('micro F1={0:1.4f}, micro P={1:1.4f}, micro R={2:1.4f}'.format(micro_f1, micro_p, micro_r))\n",
    "print('macro F1={0:1.4f}, macro P={1:1.4f}, macro R={2:1.4f}\\n'.format(macro_f1, macro_p, macro_r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "categories = [1, 2, 3, 4, 5] # –≤ –¥–∞—Ç–∞—Å–µ—Ç–µ –Ω–µ—Ç —Ç–æ–≤–∞—Ä–æ–≤ —Å–æ —Å—Ä–µ–¥–Ω–∏–º —Ä–µ–π—Ç–∏–Ω–≥–æ–º >= 4.5\n",
    "sns.heatmap(data=confusion_matrix(y_test, predicted), annot=True, fmt=\"d\", cbar=False, xticklabels=categories, yticklabels=categories)\n",
    "plt.title(\"Confusion matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ö–∞–∫ –≤–∏–¥–Ω–æ –∏–∑ –º–∞—Ç—Ä–∏—Ü—ã —Å–º–µ–∂–Ω–æ—Å—Ç–∏:\n",
    "\n",
    "* –º–æ–¥–µ–ª—å –ø—Ä–∞–≤–∏–ª—å–Ω–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–ª–∞ –æ—Ü–µ–Ω–∫—É 1 –¥–ª—è –≤—Å–µ—Ö –¥–≤—É—Ö —Ç–æ–≤–∞—Ä–æ–≤\n",
    "* –º–æ–¥–µ–ª—å —á–∞—Å—Ç–æ –æ—à–∏–±–æ—á–Ω–æ –ø—Ä–∏—Å–≤–∞–∏–≤–∞–µ—Ç –æ—Ü–µ–Ω–∫—É 3 —Ç–æ–≤–∞—Ä–æ–º —Å –æ—Ü–µ–Ω–∫–æ–π 2\n",
    "* –º–æ–¥–µ–ª—å —Ö–æ—Ä–æ—à–æ –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ—Ç –æ—Ü–µ–Ω–∫—É –¥–ª—è —Ç–æ–≤–∞—Ä–æ–≤ —Å —Ä–µ–π—Ç–∏–Ω–≥–æ–º 3, –Ω–æ –∏–Ω–æ–≥–¥–∞ –æ—à–∏–±–∞–µ—Ç—Å—è –∏ –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ—Ç –æ—Ü–µ–Ω–∫–∏ 4 –∏ 2\n",
    "* –≤ –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–µ —Å–ª—É—á–∞–µ–≤ –º–æ–¥–µ–ª—å –ø—Ä–∞–≤–∏–ª—å–Ω–æ –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ—Ç –æ—Ü–µ–Ω–∫—É 4, –Ω–æ –¥–æ–≤–æ–ª—å–Ω–æ —á–∞—Å—Ç–æ –æ—à–∏–±–æ—á–Ω–æ –ø—Ä–∏—Å–≤–∞–∏–≤–∞–µ—Ç —Ç–æ–≤–∞—Ä–∞–º —Å –æ—Ü–µ–Ω–∫–æ–π 4 –æ—Ü–µ–Ω–∫—É 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –ì—Ä–∏–¥—Å–µ—Ä—á –¥–ª—è –¥–µ—Ä–µ–≤—å–µ–≤ —Ä–µ—à–µ–Ω–∏–π —Å TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_split.py:670: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=DecisionTreeClassifier(),\n",
       "             param_grid={'criterion': ('gini', 'entropy'),\n",
       "                         'splitter': ('best', 'random')},\n",
       "             scoring=make_scorer(accuracy_score))"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_columns = list(shoes_data_new.columns)\n",
    "feature_columns = [col for col in all_columns if ('product_description_' in col)\n",
    "                  or ('reviews_' in col)]\n",
    "\n",
    "feature_columns.append('shoe_type')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(shoes_data_new_2[feature_columns], shoes_data_new_2.rounded_rating,\n",
    "                                                    test_size=0.33, random_state=42)\n",
    "\n",
    "parameters = {'criterion':('gini', 'entropy'), 'splitter':('best', 'random')}\n",
    "svc = DecisionTreeClassifier()\n",
    "scorer = make_scorer(accuracy_score)\n",
    "clf = GridSearchCV(estimator=svc, param_grid=parameters, scoring=scorer)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–õ—É—á—à–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤: \n",
      "{'criterion': 'gini', 'splitter': 'random'}\n",
      "–ó–Ω–∞—á–µ–Ω–∏—è –º–µ—Ç—Ä–∏–∫ –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ: \n",
      "acc=0.8177\n",
      "micro F1=0.8177, micro P=0.8177, micro R=0.8177\n",
      "macro F1=0.5691, macro P=0.5734, macro R=0.5655\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print('–õ—É—á—à–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤: ')\n",
    "print(clf.best_params_)\n",
    "predicted = clf.predict(X_test)\n",
    "print('–ó–Ω–∞—á–µ–Ω–∏—è –º–µ—Ç—Ä–∏–∫ –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ: ')\n",
    "predicted = clf.predict(X_test)\n",
    "acc = accuracy_score(predicted, y_test)\n",
    "micro_f1 = f1_score(predicted, y_test, average = 'micro')\n",
    "micro_p = precision_score(predicted, y_test, average = 'micro')\n",
    "micro_r = recall_score(predicted, y_test, average = 'micro')\n",
    "macro_f1 = f1_score(predicted, y_test, average = 'macro')\n",
    "macro_p = precision_score(predicted, y_test, average = 'macro')\n",
    "macro_r = recall_score(predicted, y_test, average = 'macro')\n",
    "print('acc={0:1.4f}'.format(acc))\n",
    "print('micro F1={0:1.4f}, micro P={1:1.4f}, micro R={2:1.4f}'.format(micro_f1, micro_p, micro_r))\n",
    "print('macro F1={0:1.4f}, macro P={1:1.4f}, macro R={2:1.4f}\\n'.format(macro_f1, macro_p, macro_r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "categories = [1, 2, 3, 4, 5]\n",
    "sns.heatmap(data=confusion_matrix(y_test, predicted), annot=True, fmt=\"d\", cbar=False, xticklabels=categories, yticklabels=categories)\n",
    "plt.title(\"Confusion matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ö–∞–∫ –º—ã –≤–∏–¥–∏–º –∏–∑ –º–∞—Ç—Ä–∏—Ü—ã —Å–º–µ–∂–Ω–æ—Å—Ç–∏:\n",
    "\n",
    "* –º–æ–¥–µ–ª—å –ø—Ä–∞–≤–∏–ª—å–Ω–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–ª–∞ –æ—Ü–µ–Ω–∫—É –¥–ª—è —Ç–æ–≤–∞—Ä–æ–≤ —Å —Ä–µ–π—Ç–∏–Ω–≥–∞–º–∏ 1 –∏ 2\n",
    "* –º–æ–¥–µ–ª—å —á–∞—Å—Ç–æ –æ—à–∏–±–æ—á–Ω–æ –æ—Ç–Ω–æ—Å–∏—Ç —Ç–æ–≤–∞—Ä—ã –∏–∑ —Ç—Ä–µ—Ç—å–µ–≥–æ –∫–ª–∞—Å—Å–∞ –∫ —á–µ—Ç–≤–µ—Ä—Ç–æ–º—É\n",
    "* –º–æ–¥–µ–ª—å –≤ –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–µ —Å–ª—É—á–∞–µ–≤ –ø—Ä–∞–≤–∏–ª—å–Ω–æ –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Ç–æ–≤–∞—Ä—ã —á–µ—Ç–≤–µ—Ä—Ç–æ–≥–æ –∫–ª–∞—Å—Å–∞, –Ω–æ –∏–Ω–æ–≥–¥–∞ –æ—à–∏–±–æ—á–Ω–æ –æ—Ç–Ω–æ—Å–∏—Ç –∏—Ö –∫ —Ç—Ä–µ—Ç—å–µ–º—É –∫–ª–∞—Å—Å—É\n",
    "* –º–æ–¥–µ–ª—å –≤ –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–µ —Å–ª—É—á–∞–µ–≤ –ø—Ä–∞–≤–∏–ª—å–Ω–æ –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Ç–æ–≤–∞—Ä—ã –ø—è—Ç–æ–≥–æ –∫–ª–∞—Å—Å–∞, –Ω–æ —á–∞—Å—Ç–æ –æ—à–∏–±–æ—á–Ω–æ –æ—Ç–Ω–æ—Å–∏—Ç –∏—Ö –∫ —á–µ—Ç–≤–µ—Ä—Ç–æ–º—É –∫–ª–∞—Å—Å—É"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –õ—É—á—à–∞—è –º–æ–¥–µ–ª—å —Ä–µ–≥—Ä–µ—Å—Å–∏–∏ - Ridge —Å TFIDF\n",
    "### –ü–æ–ø—Ä–æ–±—É–µ–º –ø—Ä–∏–º–µ–Ω–∏—Ç—å –∫ –Ω–µ–π –≥—Ä–∏–¥—Å–µ—Ä—á"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:190: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n",
      "  warnings.warn(\"Singular matrix in solving dual problem. Using \"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:190: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n",
      "  warnings.warn(\"Singular matrix in solving dual problem. Using \"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:190: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n",
      "  warnings.warn(\"Singular matrix in solving dual problem. Using \"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:190: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n",
      "  warnings.warn(\"Singular matrix in solving dual problem. Using \"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:190: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n",
      "  warnings.warn(\"Singular matrix in solving dual problem. Using \"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:190: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n",
      "  warnings.warn(\"Singular matrix in solving dual problem. Using \"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:190: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n",
      "  warnings.warn(\"Singular matrix in solving dual problem. Using \"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:190: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n",
      "  warnings.warn(\"Singular matrix in solving dual problem. Using \"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:190: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n",
      "  warnings.warn(\"Singular matrix in solving dual problem. Using \"\n",
      "/Users/kseniapetuhova/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:190: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n",
      "  warnings.warn(\"Singular matrix in solving dual problem. Using \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Ridge(),\n",
       "             param_grid={'alpha': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
       "                         'solver': ['auto', 'svd', 'cholesky', 'lsqr',\n",
       "                                    'sparse_cg', 'sag', 'saga']},\n",
       "             scoring=make_scorer(mean_absolute_error, greater_is_better=False))"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_columns = list(shoes_data_new.columns)\n",
    "feature_columns = [col for col in all_columns if ('product_description_' in col)\n",
    "                  or ('reviews_' in col)]\n",
    "\n",
    "feature_columns.append('shoe_type')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(shoes_data_new_2[feature_columns], shoes_data_new_2.rating_new,\n",
    "                                                    test_size=0.33, random_state=42)\n",
    "parameters = {'alpha':[i for i in range(11)], 'solver': ['auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg',\n",
    "                                                         'sag', 'saga']}\n",
    "reg = Ridge()\n",
    "scorer = make_scorer(mean_absolute_error, greater_is_better=False)\n",
    "clf = GridSearchCV(estimator=reg,param_grid=parameters, scoring=scorer)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–õ—É—á—à–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤: \n",
      "{'alpha': 1, 'solver': 'auto'}\n",
      "mean absolute error –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ =  0.22115618801406348\n"
     ]
    }
   ],
   "source": [
    "print('–õ—É—á—à–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤: ')\n",
    "print(clf.best_params_)\n",
    "predicted = clf.predict(X_test)\n",
    "m = mean_absolute_error(y_test, predicted)\n",
    "print('mean absolute error –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ = ', m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ú–æ–¥–µ–ª—å –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ —Ö–æ—Ä–æ—à–æ –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ—Ç —Ä–µ–π—Ç–∏–Ω–≥ —Ç–æ–≤–∞—Ä–æ–≤. –û–¥–Ω–∞–∫–æ, –∫–∞–∫ –º–Ω–µ –∫–∞–∂–µ—Ç—Å—è, –∑–∞–¥–∞—á–∞ —Ä–µ–≥—Ä–µ—Å—Å–∏–∏ –≤ —Å–ª—É—á–∞–µ —Å –æ—Ç–∑—ã–≤–∞–º–∏ –≤—ã–≥–ª—è–¥–∏—Ç –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω–æ, –ø–æ—Ç–æ–º—É —á—Ç–æ —Å–æ–≤—Å–µ–º –Ω–µ –ø–æ–Ω—è—Ç–Ω–∞ —Ä–∞–∑–Ω–∏—Ü–∞ –º–µ–∂–¥—É, –Ω–∞–ø—Ä–∏–º–µ—Ä, —Ä–µ–π—Ç–∏–Ω–≥–æ–º 3.7 –∏ —Ä–µ–π—Ç–∏–Ω–≥–æ–º 3.8, –µ–µ —Å–ª–æ–∂–Ω–æ –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä–æ–≤–∞—Ç—å –Ω–µ —Ç–æ–ª—å–∫–æ –º–∞—à–∏–Ω–µ, –Ω–æ –∏ —á–µ–ª–æ–≤–µ–∫—É."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –í—ã–≤–æ–¥—ã"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ß—Ç–æ–±—ã —É–ª—É—á—à–∏—Ç—å –∫–∞—á–µ—Å—Ç–≤–æ —Ä–∞–±–æ—Ç—ã –≤—Å–µ—Ö —Ç—Ä–µ—Ö –ø–æ—Å–ª–µ–¥–Ω–∏—Ö –º–æ–¥–µ–ª–µ–π, —è –±—ã –ø—Ä–µ–¥–ª–æ–∂–∏–ª–∞ –¥–æ—Å—Ç–∞–≤–∞—Ç—å –∏–∑ —Ç–µ–∫—Å—Ç–æ–≤ –æ—Ç–∑—ã–≤–æ–≤ –∏–Ω—Ç–µ–Ω—Ç—ã –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω–æ–π/–æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω–æ–π –æ—Ü–µ–Ω–∫–∏, –∞ —Ç–∞–∫–∂–µ –¥–æ–±–∞–≤–∏–ª–∞ –±—ã –≤ –∫–∞—á–µ—Å—Ç–≤–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –≤—Å—è–∫–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –ø–æ —Ç–∏–ø—É –Ω–∞–ª–∏—á–∏—è —Å–ª–æ–≤, –Ω–∞–ø–∏—Å–∞–Ω–Ω—ã—Ö –∫–∞–ø—Å–æ–º, –Ω–∞–ª–∏—á–∏–µ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –≤–æ—Å–∫–ª–∏—Ü–∞—Ç–µ–ª—å–Ω—ã—Ö –∑–Ω–∞–∫–æ–≤ –∏–ª–∏ —Ç–æ—á–µ–∫ (–∏—Å—Ö–æ–¥—è –∏–∑ –ø—Ä–µ–¥–ø–æ–ª–æ–∂–µ–Ω–∏—è, —á—Ç–æ –∑–ª–æ–π –ø–æ–∫—É–ø–∞—Ç–µ–ª—å –±–æ–ª–µ–µ —ç–º–æ—Ü–∏–æ–Ω–∞–ª–µ–Ω) –∏ —Ç.–¥."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
